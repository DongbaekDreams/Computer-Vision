{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884ce731",
   "metadata": {},
   "source": [
    "## Shared Configuration & Camera Utilities (Used by All Cells)\n",
    "\n",
    "This cell defines **all global configuration, constants, and helper functions** used throughout the notebook.  \n",
    "Nothing in this cell performs calibration or measurement by itself — it only prepares shared state and utilities.\n",
    "\n",
    "### What this cell contains\n",
    "\n",
    "#### 1. Global flags\n",
    "- **`PRE_CALIBRATED`**  \n",
    "  If `True`, later cells will load existing camera intrinsics instead of re-running calibration.\n",
    "- **`SHOW_COMPARISON`**  \n",
    "  Optional toggle for displaying raw vs undistorted comparisons in downstream cells.\n",
    "\n",
    "#### 2. Chessboard definition (ground truth geometry)\n",
    "- Defines an **8×8 chessboard** with **7×7 inner corners**.\n",
    "- Physical size is specified in millimeters and converted to meters:\n",
    "  - `BOARD_OUTER_MM` → total board width\n",
    "  - `SQUARE_M` → square size in meters\n",
    "- This geometry is the **metric reference** for calibration and measurement.\n",
    "\n",
    "#### 3. Phone camera stream configuration\n",
    "- **`CAM_BASE`** is the base URL of the phone’s IP camera web interface.\n",
    "- The actual MJPEG stream endpoint is **auto-discovered**, not hard-coded.\n",
    "\n",
    "#### 4. File locations\n",
    "- **`CALIB_DIR`**  \n",
    "  Where captured calibration frames are saved.\n",
    "- **`INTRINSICS_PATH`**  \n",
    "  `.npz` file containing saved camera intrinsics (K, distortion, metadata).\n",
    "\n",
    "#### 5. Stream discovery helpers\n",
    "Utilities that:\n",
    "- Fetch the phone’s HTML control page\n",
    "- Scrape likely video stream URLs (`<img src=…>`, `<video src=…>`)\n",
    "- Try common MJPEG endpoints\n",
    "- Test each candidate with OpenCV until a valid stream is found\n",
    "\n",
    "This allows the notebook to work across different phone camera apps without manual URL tweaking.\n",
    "\n",
    "#### 6. Chessboard object-point generator\n",
    "- `mk_object_points(...)` builds the **3D world coordinates** of all chessboard corners\n",
    "- Used during calibration and homography estimation\n",
    "- Coordinates lie in the board plane (`Z = 0`) and are expressed in **meters**\n",
    "\n",
    "#### 7. Homography quality helpers (jitter diagnostics)\n",
    "Defines utilities and thresholds used later to **evaluate homography stability**:\n",
    "- Normalize homographies for consistent scaling\n",
    "- Compute **RMS reprojection error** (in pixels)\n",
    "- Constants for rejecting unstable or noisy board detections\n",
    "\n",
    "These do **not** alter UI behavior — they are used internally to decide whether a detected board pose is trustworthy.\n",
    "\n",
    "---\n",
    "\n",
    "**In short:**  \n",
    "This cell centralizes *all shared assumptions* (board geometry, camera source, file paths) and *all low-level helpers* so the rest of the notebook can focus purely on calibration, visualization, and measurement logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac3dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# TOP CELL — Shared config + helpers (used by all cells below)\n",
    "# ============================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Notebook toggles\n",
    "# ----------------------------\n",
    "PRE_CALIBRATED = True\n",
    "SHOW_COMPARISON = False\n",
    "\n",
    "# ----------------------------\n",
    "# Board config\n",
    "# ----------------------------\n",
    "BOARD_OUTER_MM = 336.0\n",
    "SQUARE_MM = BOARD_OUTER_MM / 8.0\n",
    "SQUARE_M = SQUARE_MM / 1000.0\n",
    "PATTERN_SIZE = (7, 7)  # 8x8 squares => 7x7 inner corners\n",
    "\n",
    "# ----------------------------\n",
    "# Phone stream base page\n",
    "# ----------------------------\n",
    "CAM_BASE = \"http://192.168.1.70:8080/\"  # base control page that works in your browser\n",
    "\n",
    "# ----------------------------\n",
    "# Files\n",
    "# ----------------------------\n",
    "CALIB_DIR = Path(\"calib_frames_phone\")\n",
    "INTRINSICS_PATH = \"camera_intrinsics_phone.npz\"\n",
    "\n",
    "# ----------------------------\n",
    "# Capture preview sizing\n",
    "# ----------------------------\n",
    "PREVIEW_MAX_W = 1600\n",
    "PREVIEW_MAX_H = 900\n",
    "\n",
    "# ----------------------------\n",
    "# Stream endpoint discovery\n",
    "# ----------------------------\n",
    "COMMON_STREAM_PATHS = [\n",
    "    \"video\",\n",
    "    \"videofeed\",\n",
    "    \"mjpeg\", \"mjpegfeed\",\n",
    "    \"live\", \"stream\",\n",
    "    \"?action=stream\",\n",
    "    \"video?x.mjpeg\",\n",
    "    \"mjpg/video.mjpg\",\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Live measurement config (CELL 3 reads these)\n",
    "# ----------------------------\n",
    "CAM_INDEX = 0\n",
    "CAPTURE_W = 3840\n",
    "CAPTURE_H = 2160\n",
    "\n",
    "# Detection cadence / preprocess\n",
    "DETECT_EVERY_N = 12\n",
    "DETECT_SCALE = 0.45\n",
    "CLAHE_ON = True\n",
    "SB_FIRST = True\n",
    "\n",
    "# Tracking / smoothing\n",
    "TRACK_MIN_FRAC = 0.75\n",
    "CORNER_EMA_ALPHA = 0.20\n",
    "REDETECT_ON_TRACK_FAIL = True\n",
    "\n",
    "# LK safety rails (prevents collapse / shoot-off)\n",
    "FB_ERR_MAX_PX = 1.25\n",
    "MAX_JUMP_PX = 30.0\n",
    "\n",
    "# Display sizing\n",
    "DISPLAY_MAX_W = 1600\n",
    "DISPLAY_MAX_H = 900\n",
    "\n",
    "# Point rendering\n",
    "POINT_RING_R = 8\n",
    "POINT_RING_TH = 2\n",
    "POINT_CENTER_R = 1\n",
    "POINT_HIT_R_FULL = 12\n",
    "LABEL_SCALE = 0.6\n",
    "\n",
    "# Zoom\n",
    "zoom_factor = 4\n",
    "zoom_radius = 180\n",
    "zoom_win = \"zoom\"\n",
    "\n",
    "# ----------------------------\n",
    "# URL discovery helpers\n",
    "# ----------------------------\n",
    "def _fetch_html(url, timeout=3.0):\n",
    "    req = urllib.request.Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    with urllib.request.urlopen(req, timeout=timeout) as r:\n",
    "        return r.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def _extract_stream_urls_from_html(base_url, html):\n",
    "    candidates = set()\n",
    "    for m in re.finditer(r'(?:href|src)\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, flags=re.IGNORECASE):\n",
    "        u = m.group(1).strip()\n",
    "        if not u:\n",
    "            continue\n",
    "        low = u.lower()\n",
    "        if any(k in low for k in [\"mjpeg\", \"mjpg\", \"videofeed\", \"video\", \"stream\", \"action=stream\"]):\n",
    "            candidates.add(urllib.parse.urljoin(base_url, u))\n",
    "    return list(candidates)\n",
    "\n",
    "def _try_open_url(url):\n",
    "    backends = [None, cv2.CAP_MSMF]\n",
    "    try:\n",
    "        backends.append(cv2.CAP_FFMPEG)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    for be in backends:\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(url) if be is None else cv2.VideoCapture(url, be)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if cap is None or not cap.isOpened():\n",
    "            try:\n",
    "                cap.release()\n",
    "            except:\n",
    "                pass\n",
    "            continue\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None and frame.size > 0:\n",
    "            return cap, frame\n",
    "        cap.release()\n",
    "    return None, None\n",
    "\n",
    "def open_phone_cap():\n",
    "    base = CAM_BASE if CAM_BASE.endswith(\"/\") else (CAM_BASE + \"/\")\n",
    "    html = _fetch_html(base, timeout=3.0)\n",
    "    scraped = _extract_stream_urls_from_html(base, html)\n",
    "    fallbacks = [urllib.parse.urljoin(base, p) for p in COMMON_STREAM_PATHS]\n",
    "\n",
    "    seen = set()\n",
    "    candidates = []\n",
    "    for u in scraped + fallbacks:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            candidates.append(u)\n",
    "\n",
    "    for u in candidates:\n",
    "        cap, frame = _try_open_url(u)\n",
    "        if cap is not None:\n",
    "            return cap, u, frame\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"Browser opens CAM_BASE, but OpenCV can't find a readable stream endpoint.\\n\"\n",
    "        \"Fix:\\n\"\n",
    "        \"  - Open CAM_BASE in your browser\\n\"\n",
    "        \"  - Right-click the video -> Copy video address\\n\"\n",
    "        \"  - Set CAM_BASE to that direct stream URL (or paste it here)\\n\"\n",
    "    )\n",
    "\n",
    "def mk_object_points(pattern_size, square_m):\n",
    "    nx, ny = pattern_size\n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2) * square_m\n",
    "    return objp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e21e0",
   "metadata": {},
   "source": [
    "## Capture Calibration Frames (Phone Stream) + Load or Compute Camera Intrinsics\n",
    "\n",
    "This cell produces the camera intrinsics needed for undistortion and metric measurements:\n",
    "\n",
    "- **`K`**: camera matrix (focal lengths + principal point)  \n",
    "- **`dist`**: lens distortion coefficients  \n",
    "- **`image_size`**: resolution the intrinsics were calibrated for\n",
    "\n",
    "It has two independent stages:\n",
    "\n",
    "### A) Capture calibration frames (optional)\n",
    "\n",
    "Runs only when `PRE_CALIBRATED = False`.\n",
    "\n",
    "- Opens the phone camera stream using `open_phone_cap()` (auto-discovers the MJPEG endpoint).\n",
    "- Shows a **mirrored + downscaled preview** for usability.\n",
    "- Saves **full-resolution** frames to `CALIB_DIR` when you press **SPACE**.\n",
    "- Press **ESC** to quit capture.\n",
    "\n",
    "The saved frames are later used for chessboard corner detection and camera calibration.\n",
    "\n",
    "### B) Load or calibrate intrinsics\n",
    "\n",
    "- If `PRE_CALIBRATED = True`:\n",
    "  - Loads `K`, `dist`, and `image_size` from `INTRINSICS_PATH`.\n",
    "\n",
    "- If `PRE_CALIBRATED = False`:\n",
    "  - Builds the board’s known 3D corner coordinates (`objp`) using `mk_object_points(...)`.\n",
    "  - For each saved image:\n",
    "    - Converts to grayscale\n",
    "    - Applies **CLAHE** to boost local contrast (often helps phone streams)\n",
    "    - Detects chessboard corners using:\n",
    "      1) **`findChessboardCornersSB`** (preferred, more robust), tried on both normal and inverted images  \n",
    "      2) Fallback to classic **`findChessboardCorners`** with **subpixel refinement**\n",
    "  - Runs `cv2.calibrateCamera(...)` to estimate `K` and `dist`.\n",
    "  - Saves results (plus metadata like board size and square length) to `INTRINSICS_PATH`.\n",
    "\n",
    "**Output of this cell:**  \n",
    "A valid `(K, dist)` pair in memory (and optionally persisted to disk), which later cells use for undistortion and homography-based measurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9160bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping capture (PRE_CALIBRATED=True)\n",
      "Loaded intrinsics from camera_intrinsics_phone.npz\n",
      "image_size: (np.int64(1920), np.int64(1080))\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# (A) Capture frames (optional)\n",
    "# ----------------------------\n",
    "# Captures full-res frames from the phone stream into CALIB_DIR.\n",
    "# Preview is mirrored and downscaled only for usability; saved images are original frames.\n",
    "if not PRE_CALIBRATED:\n",
    "    CALIB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cap, chosen_url, first = open_phone_cap()\n",
    "    h0, w0 = first.shape[:2]\n",
    "    print(\"Opened stream:\", chosen_url)\n",
    "    print(f\"Stream resolution: {w0}x{h0}\")\n",
    "    print(\"SPACE=save | ESC=quit\")\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            print(\"Frame read failed; exiting.\")\n",
    "            break\n",
    "\n",
    "        preview = cv2.flip(frame, 1)\n",
    "\n",
    "        ph, pw = preview.shape[:2]\n",
    "        scale = min(PREVIEW_MAX_W / pw, PREVIEW_MAX_H / ph, 1.0)\n",
    "        if scale < 1.0:\n",
    "            preview = cv2.resize(\n",
    "                preview,\n",
    "                (int(pw * scale), int(ph * scale)),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"PHONE: SPACE=save | ESC=quit\", preview)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 27:  # ESC\n",
    "            print(\"ESC pressed; exiting.\")\n",
    "            break\n",
    "\n",
    "        if key == 32:  # SPACE\n",
    "            fname = CALIB_DIR / f\"frame_{idx:04d}.jpg\"\n",
    "            ok_write = cv2.imwrite(str(fname), frame, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "            print(f\"Saved {fname}\" if ok_write else f\"Failed to save {fname}\")\n",
    "            idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Skipping capture (PRE_CALIBRATED=True)\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# (B) Calibrate or load intrinsics\n",
    "# ----------------------------\n",
    "# If PRE_CALIBRATED:\n",
    "#   - Load K, dist, image_size from INTRINSICS_PATH\n",
    "# Else:\n",
    "#   - Detect chessboard corners on saved images\n",
    "#   - Run cv2.calibrateCamera\n",
    "#   - Save to INTRINSICS_PATH\n",
    "if PRE_CALIBRATED:\n",
    "    z = np.load(INTRINSICS_PATH, allow_pickle=True)\n",
    "    K = z[\"camera_matrix\"]\n",
    "    dist = z[\"dist_coeffs\"]\n",
    "    image_size = tuple(z[\"image_size\"])\n",
    "    print(\"Loaded intrinsics from\", INTRINSICS_PATH)\n",
    "    print(\"image_size:\", image_size)\n",
    "else:\n",
    "    objp = mk_object_points(PATTERN_SIZE, SQUARE_M)\n",
    "\n",
    "    objpoints = []  # per-image 3D corner locations in board coordinates\n",
    "    imgpoints = []  # per-image 2D detected corner locations in image coordinates\n",
    "    image_size = None\n",
    "\n",
    "    SB_FLAGS = (cv2.CALIB_CB_EXHAUSTIVE | cv2.CALIB_CB_ACCURACY)\n",
    "    CLASSIC_FLAGS = (cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
    "\n",
    "    # CLAHE boosts local contrast, often improves chessboard detection on phone streams.\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "\n",
    "    img_files = sorted(glob.glob(str(CALIB_DIR / \"*.jpg\")))\n",
    "    if not img_files:\n",
    "        raise RuntimeError(f\"No images found in {CALIB_DIR}. Capture frames first (PRE_CALIBRATED=False).\")\n",
    "\n",
    "    for fname in img_files:\n",
    "        img = cv2.imread(fname)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calibration assumes consistent image size for all samples.\n",
    "        if image_size is None:\n",
    "            image_size = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "        # Preprocess for detection.\n",
    "        g = clahe.apply(gray)\n",
    "\n",
    "        # Preferred: findChessboardCornersSB (robust) on normal and inverted.\n",
    "        ok, corners = cv2.findChessboardCornersSB(g, PATTERN_SIZE, SB_FLAGS)\n",
    "        if not ok:\n",
    "            ok, corners = cv2.findChessboardCornersSB(255 - g, PATTERN_SIZE, SB_FLAGS)\n",
    "\n",
    "        # Fallback: classic detector + subpixel refinement (normal only, as in your code).\n",
    "        if not ok:\n",
    "            ok, corners = cv2.findChessboardCorners(g, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "            if ok:\n",
    "                corners = cv2.cornerSubPix(g, corners, (11, 11), (-1, -1), term)\n",
    "\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        objpoints.append(objp.copy())\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "    n = len(imgpoints)\n",
    "    print(\"chessboard detections:\", n, \"image_size:\", image_size)\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No usable chessboard detections. Improve lighting/contrast, reduce glare, \"\n",
    "            \"fill frame more, add varied angles.\"\n",
    "        )\n",
    "\n",
    "    rms, K, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_size, None, None)\n",
    "\n",
    "    np.savez(\n",
    "        INTRINSICS_PATH,\n",
    "        rms=float(rms),\n",
    "        camera_matrix=K,\n",
    "        dist_coeffs=dist,\n",
    "        image_size=np.array(image_size, dtype=int),\n",
    "        pattern_size=np.array(PATTERN_SIZE, dtype=int),\n",
    "        square_length_m=float(SQUARE_M),\n",
    "        board_outer_mm=float(BOARD_OUTER_MM),\n",
    "        cam_base=str(CAM_BASE),\n",
    "    )\n",
    "\n",
    "    print(\"Saved intrinsics to\", INTRINSICS_PATH)\n",
    "    print(\"RMS reprojection error:\", float(rms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840388f",
   "metadata": {},
   "source": [
    "## Optional Undistortion Sanity Check (Raw vs Undistorted vs Difference)\n",
    "\n",
    "This block runs only when `SHOW_COMPARISON = True`.  \n",
    "It provides a visual verification that the loaded camera intrinsics (`K`, `dist`) are being applied correctly to the live video stream.\n",
    "\n",
    "---\n",
    "\n",
    "### What this block does\n",
    "\n",
    "#### 1. Camera source selection\n",
    "- `SOURCE = \"phone_url\"`  \n",
    "  Opens the phone camera stream using `open_phone_cap()`, which auto-discovers the MJPEG endpoint.\n",
    "- `SOURCE = \"device\"`  \n",
    "  Opens a local webcam via OpenCV device capture.\n",
    "\n",
    "This assumes the intrinsics currently loaded **correspond to the camera source opened here**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Undistortion using an optimal projection (`newK`)\n",
    "For each frame:\n",
    "- Computes `newK = cv2.getOptimalNewCameraMatrix(...)` once per resolution.\n",
    "- Applies undistortion using the loaded intrinsics (`K`, `dist`) to produce an undistorted frame.\n",
    "\n",
    "`ALPHA_NEWK` controls the projection tradeoff:\n",
    "- `0.0` → crop to valid pixels (minimal black borders)\n",
    "- `1.0` → preserve full field of view (may introduce black borders)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Difference visualization (raw vs undistorted)\n",
    "To make distortion effects explicit:\n",
    "- Convert raw and undistorted frames to grayscale\n",
    "- Compute the absolute per-pixel difference between them\n",
    "- Optionally blur the difference image (`BLUR_K`) to suppress speckle\n",
    "- Apply a color map to emphasize magnitude of change\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Hotspot detection\n",
    "Identifies regions where undistortion significantly alters pixel values:\n",
    "- Thresholds the difference image (`DIFF_THRESH`)\n",
    "- Cleans the binary mask using morphological open + dilate\n",
    "- Overlays a red tint onto hotspot pixels in the undistorted frame\n",
    "- Reports the percentage of hotspot pixels as `hotspots: XX.XX%`\n",
    "\n",
    "This helps confirm that distortion correction is spatially coherent and reasonable.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. 2×2 diagnostic mosaic\n",
    "Displays four synchronized views:\n",
    "- **RAW** — original frame\n",
    "- **UNDISTORTED** — corrected frame\n",
    "- **ABS DIFF** — magnitude of pixel changes caused by undistortion\n",
    "- **HOTSPOTS** — undistorted frame with strong-change regions highlighted\n",
    "\n",
    "Press **ESC** to exit the sanity check view.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3d1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_COMPARISON:\n",
    "    # Assumes: K, dist already exist (and match the camera you open here)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Choose ONE source\n",
    "    # ----------------------------\n",
    "    SOURCE = \"phone_url\"      # \"device\" or \"phone_url\"\n",
    "\n",
    "    # local webcam (used if SOURCE=\"device\")\n",
    "    CAM_INDEX = 0\n",
    "    CAPTURE_W = 3840\n",
    "    CAPTURE_H = 2160\n",
    "\n",
    "    # phone base page (used if SOURCE=\"phone_url\")\n",
    "    CAM_BASE = CAM_BASE  # uses top-cell CAM_BASE by default\n",
    "\n",
    "    # ----------------------------\n",
    "    # Display layout\n",
    "    # ----------------------------\n",
    "    TILE_W = 640\n",
    "    TILE_H = 360\n",
    "\n",
    "    DIFF_THRESH = 25\n",
    "    BLUR_K = 5\n",
    "    ALPHA_NEWK = 0.0  # 0=crop to valid pixels (reduces black borders), 1=keep all pixels\n",
    "\n",
    "    def open_device_cap():\n",
    "        \"\"\"\n",
    "        Opens local webcam in MJPG mode at requested resolution.\n",
    "        Returns: (cap, src_string, first_frame)\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)\n",
    "        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_W)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_H)\n",
    "        if not cap.isOpened():\n",
    "            cap.release()\n",
    "            raise RuntimeError(\"Failed to open camera device\")\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            cap.release()\n",
    "            raise RuntimeError(\"Opened device camera but failed to read a frame\")\n",
    "        return cap, f\"device:{CAM_INDEX}\", frame\n",
    "\n",
    "    def resize_tile(img):\n",
    "        \"\"\"Fixed-size tiles for a 2x2 mosaic.\"\"\"\n",
    "        return cv2.resize(img, (TILE_W, TILE_H), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def label(img, text):\n",
    "        \"\"\"Readable tile labels (white text with black outline).\"\"\"\n",
    "        out = img.copy()\n",
    "        cv2.putText(out, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "        cv2.putText(out, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        return out\n",
    "\n",
    "    # ----------------------------\n",
    "    # Open selected source\n",
    "    # ----------------------------\n",
    "    if SOURCE == \"phone_url\":\n",
    "        cap, chosen_url, first = open_phone_cap()\n",
    "        src = f\"phone:{chosen_url}\"\n",
    "    elif SOURCE == \"device\":\n",
    "        cap, src, first = open_device_cap()\n",
    "    else:\n",
    "        raise ValueError('SOURCE must be \"phone_url\" or \"device\"')\n",
    "\n",
    "    print(\"ESC=quit | source:\", src)\n",
    "\n",
    "    # Cache newK by frame size.\n",
    "    newK = None\n",
    "    last_size = None\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            break\n",
    "\n",
    "        # ----------------------------\n",
    "        # Undistort with an optimal new camera matrix (newK)\n",
    "        # ----------------------------\n",
    "        # getOptimalNewCameraMatrix chooses a new projection matrix that trades off:\n",
    "        #   - cropping away invalid pixels (alpha=0)\n",
    "        #   - vs keeping all pixels (alpha=1) which may add black borders\n",
    "        h, w = frame.shape[:2]\n",
    "        if newK is None or last_size != (w, h):\n",
    "            newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), ALPHA_NEWK)\n",
    "            last_size = (w, h)\n",
    "\n",
    "        und = cv2.undistort(frame, K, dist, None, newK)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Diff view: where undistortion changes pixels the most\n",
    "        # ----------------------------\n",
    "        g_raw = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        g_und = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        diff = cv2.absdiff(g_raw, g_und)\n",
    "\n",
    "        # Optional blur to reduce speckle in diff/hotspot mask.\n",
    "        if BLUR_K and BLUR_K > 0:\n",
    "            k = BLUR_K if (BLUR_K % 2 == 1) else (BLUR_K + 1)\n",
    "            diff = cv2.GaussianBlur(diff, (k, k), 0)\n",
    "\n",
    "        diff_color = cv2.applyColorMap(diff, cv2.COLORMAP_TURBO)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Hotspot mask: threshold + morphology + overlay\n",
    "        # ----------------------------\n",
    "        mask = (diff >= DIFF_THRESH).astype(np.uint8) * 255\n",
    "        k5 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k5)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, k5)\n",
    "\n",
    "        overlay = und.copy()\n",
    "        m = (mask > 0)\n",
    "\n",
    "        # Blend red into hotspot pixels (same math as your code).\n",
    "        if m.any():\n",
    "            over_f = overlay.astype(np.float32)\n",
    "            red = np.array([0, 0, 255], dtype=np.float32)\n",
    "            over_f[m] = 0.6 * over_f[m] + 0.4 * red\n",
    "            overlay = over_f.astype(np.uint8)\n",
    "\n",
    "        hotspot_pct = 100.0 * float(np.count_nonzero(mask)) / float(mask.size)\n",
    "        overlay = label(overlay, f\"hotspots: {hotspot_pct:.2f}%\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # 2x2 mosaic\n",
    "        # ----------------------------\n",
    "        raw_t  = label(resize_tile(frame),      \"RAW\")\n",
    "        und_t  = label(resize_tile(und),        \"UNDISTORTED\")\n",
    "        diff_t = label(resize_tile(diff_color), \"ABS DIFF\")\n",
    "        over_t = label(resize_tile(overlay),    \"HOTSPOTS\")\n",
    "\n",
    "        top = np.hstack([raw_t, und_t])\n",
    "        bot = np.hstack([diff_t, over_t])\n",
    "        mosaic = np.vstack([top, bot])\n",
    "\n",
    "        cv2.imshow(\"Calibration Sanity Check\", mosaic)\n",
    "\n",
    "        if (cv2.waitKey(1) & 0xFF) == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc8936",
   "metadata": {},
   "source": [
    "## Shared Configuration & Infrastructure (Top Cell)\n",
    "\n",
    "This cell defines **all global configuration and shared helpers** used by the calibration, sanity-check, and live-measurement cells below. Nothing in here performs live processing; it only establishes constants, tunable parameters, and reusable utilities so later cells do not duplicate or hard-code behavior.\n",
    "\n",
    "### What lives here and why\n",
    "\n",
    "#### Board geometry\n",
    "- Defines the physical chessboard layout (`PATTERN_SIZE`, `SQUARE_M`) in **real-world units**.\n",
    "- This is the single source of truth for both camera calibration and image→world mapping.\n",
    "\n",
    "#### Camera + stream configuration\n",
    "- Specifies the phone stream base URL (`CAM_BASE`) and local webcam fallback (`CAM_INDEX`, resolution).\n",
    "- Includes helpers that **discover the actual MJPEG endpoint** from the phone’s control page and verify that OpenCV can read frames from it.\n",
    "\n",
    "#### Calibration I/O\n",
    "- Paths for saved calibration frames and camera intrinsics (`INTRINSICS_PATH`).\n",
    "- Used consistently by calibration, validation, and measurement cells to ensure the **same camera model** is applied everywhere.\n",
    "\n",
    "#### Detection and tracking parameters\n",
    "- Chessboard detection cadence and preprocessing (`DETECT_EVERY_N`, `DETECT_SCALE`, `CLAHE_ON`, `SB_FIRST`).\n",
    "- Corner tracking and smoothing controls (`CORNER_EMA_ALPHA`, `TRACK_MIN_FRAC`, `REDETECT_ON_TRACK_FAIL`).\n",
    "- Safety rails for optical-flow tracking (`FB_ERR_MAX_PX`, `MAX_JUMP_PX`) that prevent catastrophic collapses or jump-offs.\n",
    "\n",
    "These parameters are intentionally centralized so tracking stability can be tuned **without touching algorithmic code**.\n",
    "\n",
    "#### Display and interaction\n",
    "- Display scaling limits (`DISPLAY_MAX_W`, `DISPLAY_MAX_H`) used to fit frames on screen while keeping all math in full-resolution coordinates.\n",
    "- Marker rendering sizes and hit-testing radii for consistent UI behavior.\n",
    "- Zoom configuration (`zoom_factor`, `zoom_radius`, `zoom_win`) shared by main and zoom views.\n",
    "\n",
    "#### Shared helpers\n",
    "- URL scraping and stream-opening utilities for the phone camera.\n",
    "- Chessboard object-point generator used during calibration.\n",
    "- These functions are reused verbatim across cells to avoid subtle inconsistencies.\n",
    "\n",
    "### Design intent\n",
    "- **Configuration lives here. Runtime state does not.**\n",
    "- All downstream cells assume these names exist and only implement processing logic.\n",
    "- If a value here changes, behavior changes everywhere in a controlled, predictable way.\n",
    "\n",
    "This cell should be executed once at the start of the notebook and left untouched during normal experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC=quit | C=clear | P=print | RClick toggle zoom | source: phone:http://192.168.1.70:8080/video\n",
      "ESC=quit | C=clear | P=print | RClick toggle zoom\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Purpose\n",
    "# ----------------------------\n",
    "# Live measurement:\n",
    "#   - Open camera (phone stream if available, else local webcam)\n",
    "#   - Undistort frames using saved intrinsics (K, dist)\n",
    "#   - Keep a stable chessboard pose estimate:\n",
    "#       * Periodic re-detection of all corners (anchors the solution)\n",
    "#       * Per-frame LK optical-flow tracking in between detections (reduces jitter)\n",
    "#       * Robust gating (prevents “collapse to center” / “shoot off” failures)\n",
    "#       * EMA smoothing of corner positions before computing homography (reduces jitter)\n",
    "#       * RANSAC homography fit (a few bad points won’t trash H)\n",
    "#   - You click 4 points; if board pose is valid, those 4 points are mapped to the board\n",
    "#     plane (meters) and width/height are reported.\n",
    "\n",
    "# ----------------------------\n",
    "# Runtime state\n",
    "# ----------------------------\n",
    "zoom_on = False\n",
    "zoom_center = None\n",
    "zoom_win = \"zoom\"\n",
    "\n",
    "pts = []            # clicked points in FULL-RES undistorted image coords (float x,y)\n",
    "drag_i = None\n",
    "cycle_i = 0\n",
    "last_dims_m = None\n",
    "\n",
    "newK = None\n",
    "last_size = None\n",
    "\n",
    "_last_zoom_origin = None\n",
    "_frame_i = 0\n",
    "\n",
    "# Board / homography state (FULL-RES undistorted image coords)\n",
    "_have_H = False\n",
    "_Hinv = None\n",
    "\n",
    "# Corner state (N = PATTERN_SIZE[0] * PATTERN_SIZE[1])\n",
    "_corners_full = None         # latest accepted corners (N,1,2) float32\n",
    "_corners_smooth = None       # EMA-smoothed corners (N,1,2) float32\n",
    "_prev_gray = None            # previous undistorted grayscale for LK tracking\n",
    "\n",
    "# ----------------------------\n",
    "# Load intrinsics\n",
    "# ----------------------------\n",
    "z = np.load(INTRINSICS_PATH, allow_pickle=True)\n",
    "K = z[\"camera_matrix\"]\n",
    "dist = z[\"dist_coeffs\"]\n",
    "\n",
    "# ----------------------------\n",
    "# Open camera (AUTO: phone stream else local webcam)\n",
    "# ----------------------------\n",
    "def _open_device():\n",
    "    cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_W)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_H)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        return None, None\n",
    "    ok, frame = cap.read()\n",
    "    if not ok or frame is None or frame.size == 0:\n",
    "        cap.release()\n",
    "        return None, None\n",
    "    return cap, frame\n",
    "\n",
    "def open_cam_auto():\n",
    "    # Try phone stream first (open_phone_cap() comes from your shared top cell)\n",
    "    try:\n",
    "        cap, url, frame = open_phone_cap()\n",
    "        return cap, f\"phone:{url}\", frame\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback to local device camera\n",
    "    cap2, frame2 = _open_device()\n",
    "    if cap2 is not None:\n",
    "        return cap2, f\"device:{CAM_INDEX}\", frame2\n",
    "\n",
    "    raise RuntimeError(\"Couldn't open phone stream OR local webcam.\")\n",
    "\n",
    "cap, src, first = open_cam_auto()\n",
    "print(\"ESC=quit | C=clear | P=print | RClick toggle zoom | source:\", src)\n",
    "\n",
    "# ----------------------------\n",
    "# Geometry / drawing helpers\n",
    "# ----------------------------\n",
    "def compute_display_scale(h, w):\n",
    "    # Display scaling only; all computations remain in full-res coordinates.\n",
    "    return min(DISPLAY_MAX_W / w, DISPLAY_MAX_H / h, 1.0)\n",
    "\n",
    "def to_full_res(x, y, scale):\n",
    "    # Mouse coords (display) -> full-res coords (undistorted frame space)\n",
    "    return int(x / scale), int(y / scale)\n",
    "\n",
    "def to_disp(x_full, y_full, scale):\n",
    "    # Full-res coords -> display coords\n",
    "    return int(x_full * scale), int(y_full * scale)\n",
    "\n",
    "def nearest_point_index_full(x, y, pts_list, r=POINT_HIT_R_FULL):\n",
    "    # Find nearest clicked point within hit radius (full-res coordinates)\n",
    "    if not pts_list:\n",
    "        return None\n",
    "    p = np.asarray(pts_list, dtype=np.float32)\n",
    "    d2 = (p[:, 0] - x) ** 2 + (p[:, 1] - y) ** 2\n",
    "    i = int(np.argmin(d2))\n",
    "    return i if d2[i] <= r * r else None\n",
    "\n",
    "def order_quad(pts4):\n",
    "    # Stable ordering for drawing/measuring: sort by angle around centroid, then rotate so top-left is first\n",
    "    pts4 = np.asarray(pts4, dtype=np.float32)\n",
    "    c = pts4.mean(axis=0)\n",
    "    ang = np.arctan2(pts4[:, 1] - c[1], pts4[:, 0] - c[0])\n",
    "    pts4 = pts4[np.argsort(ang)]\n",
    "    s = pts4.sum(axis=1)\n",
    "    i0 = int(np.argmin(s))\n",
    "    return np.roll(pts4, -i0, axis=0)\n",
    "\n",
    "def quad_wh_m(world_xy4):\n",
    "    # Compute width/height as avg of opposite edges in board-plane metric coords\n",
    "    p = np.asarray(world_xy4, dtype=np.float64)\n",
    "    d01 = np.linalg.norm(p[1] - p[0])\n",
    "    d12 = np.linalg.norm(p[2] - p[1])\n",
    "    d23 = np.linalg.norm(p[3] - p[2])\n",
    "    d30 = np.linalg.norm(p[0] - p[3])\n",
    "    w = 0.5 * (d01 + d23)\n",
    "    h = 0.5 * (d12 + d30)\n",
    "    return w, h\n",
    "\n",
    "def zoom_crop_bounds(img_shape, center_xy, radius):\n",
    "    h, w = img_shape[:2]\n",
    "    cx, cy = center_xy\n",
    "    x1 = max(0, cx - radius); x2 = min(w, cx + radius)\n",
    "    y1 = max(0, cy - radius); y2 = min(h, cy + radius)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def make_zoom_view(img_bgr, center_xy, radius, factor):\n",
    "    # Crop around zoom_center in full-res, then scale up by zoom_factor for a zoom window\n",
    "    x1, y1, x2, y2 = zoom_crop_bounds(img_bgr.shape, center_xy, radius)\n",
    "    crop = img_bgr[y1:y2, x1:x2].copy()\n",
    "    if crop.size == 0:\n",
    "        return None, None\n",
    "    zoom = cv2.resize(crop, None, fx=factor, fy=factor, interpolation=cv2.INTER_NEAREST)\n",
    "    zh, zw = zoom.shape[:2]\n",
    "    cv2.line(zoom, (zw // 2, 0), (zw // 2, zh), (0, 255, 0), 1)\n",
    "    cv2.line(zoom, (0, zh // 2), (zw, zh // 2), (0, 255, 0), 1)\n",
    "    return zoom, (x1, y1)\n",
    "\n",
    "def draw_marker(img, x, y, color=(0, 255, 0), ring_r=POINT_RING_R, ring_th=POINT_RING_TH, center_r=POINT_CENTER_R):\n",
    "    # Hollow ring + center dot marker; size is in screen pixels (constant in main + zoom)\n",
    "    x = int(round(x)); y = int(round(y))\n",
    "    cv2.circle(img, (x, y), ring_r, color, ring_th, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, (x, y), center_r, color, -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "def draw_text(img, lines, x=18, y=40, dy=34):\n",
    "    # White text with black outline for readability\n",
    "    for i, s in enumerate(lines):\n",
    "        yy = y + i * dy\n",
    "        cv2.putText(img, s, (x, yy), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 0), 5)\n",
    "        cv2.putText(img, s, (x, yy), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (255, 255, 255), 2)\n",
    "\n",
    "# ----------------------------\n",
    "# Mouse callbacks\n",
    "# ----------------------------\n",
    "main_win = \"Measure: LClick add/drag | RClick zoom toggle | C clear | P print | ESC quit\"\n",
    "\n",
    "def mouse_zoom(event, x, y, flags, param):\n",
    "    # Zoom window mouse uses zoom-factor mapping back to full-res coords\n",
    "    global pts, drag_i, cycle_i, zoom_on, zoom_center, _last_zoom_origin\n",
    "\n",
    "    if not zoom_on or zoom_center is None or _last_zoom_origin is None:\n",
    "        return\n",
    "\n",
    "    ox, oy = _last_zoom_origin\n",
    "    fx = float(ox + (x / zoom_factor))\n",
    "    fy = float(oy + (y / zoom_factor))\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        zoom_on = False\n",
    "        zoom_center = None\n",
    "        try:\n",
    "            cv2.destroyWindow(zoom_win)\n",
    "        except:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        i = nearest_point_index_full(fx, fy, pts, r=POINT_HIT_R_FULL)\n",
    "        if i is not None:\n",
    "            drag_i = i\n",
    "            pts[drag_i] = (fx, fy)\n",
    "            return\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            drag_i = cycle_i\n",
    "            cycle_i = (cycle_i + 1) % 4\n",
    "            pts[drag_i] = (fx, fy)\n",
    "            return\n",
    "\n",
    "        if len(pts) < 4:\n",
    "            pts.append((fx, fy))\n",
    "            return\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drag_i is not None:\n",
    "            pts[drag_i] = (fx, fy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drag_i = None\n",
    "\n",
    "def mouse_main(event, x, y, flags, param):\n",
    "    # Main window mouse: add/drag points; right click toggles zoom\n",
    "    global pts, drag_i, cycle_i, zoom_on, zoom_center, disp_scale\n",
    "\n",
    "    fx, fy = to_full_res(x, y, disp_scale)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        if not zoom_on:\n",
    "            zoom_center = (fx, fy)\n",
    "            zoom_on = True\n",
    "            cv2.namedWindow(zoom_win)\n",
    "            cv2.setMouseCallback(zoom_win, mouse_zoom)\n",
    "        else:\n",
    "            zoom_on = False\n",
    "            zoom_center = None\n",
    "            try:\n",
    "                cv2.destroyWindow(zoom_win)\n",
    "            except:\n",
    "                pass\n",
    "        return\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        i = nearest_point_index_full(fx, fy, pts, r=POINT_HIT_R_FULL)\n",
    "\n",
    "        if i is not None:\n",
    "            drag_i = i\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "            return\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            drag_i = cycle_i\n",
    "            cycle_i = (cycle_i + 1) % 4\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "            return\n",
    "\n",
    "        if len(pts) < 4:\n",
    "            pts.append((float(fx), float(fy)))\n",
    "            return\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drag_i is not None:\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drag_i = None\n",
    "\n",
    "cv2.namedWindow(main_win)\n",
    "cv2.setMouseCallback(main_win, mouse_main)\n",
    "\n",
    "# ----------------------------\n",
    "# Chessboard detection setup\n",
    "# ----------------------------\n",
    "# world_xy: board-plane coordinates of each inner corner in meters (same indexing as OpenCV detection output)\n",
    "nx, ny = PATTERN_SIZE\n",
    "world_xy = (np.mgrid[0:nx, 0:ny].T.reshape(-1, 2).astype(np.float32) * float(SQUARE_M))\n",
    "\n",
    "SB_FLAGS = (cv2.CALIB_CB_EXHAUSTIVE | cv2.CALIB_CB_ACCURACY)\n",
    "CLASSIC_FLAGS = (cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)) if CLAHE_ON else None\n",
    "\n",
    "def detect_board_fast(gray_full):\n",
    "    # Detect corners on a downscaled image for speed, then scale coordinates back up.\n",
    "    if DETECT_SCALE != 1.0:\n",
    "        g = cv2.resize(gray_full, (0, 0), fx=DETECT_SCALE, fy=DETECT_SCALE, interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        g = gray_full\n",
    "\n",
    "    # CLAHE improves local contrast; helps on phone streams / glarey boards.\n",
    "    g1 = clahe.apply(g) if clahe is not None else g\n",
    "\n",
    "    # Prefer SB detector (more robust); try normal then inverted.\n",
    "    if SB_FIRST:\n",
    "        ok, corners = cv2.findChessboardCornersSB(g1, PATTERN_SIZE, SB_FLAGS)\n",
    "        if ok:\n",
    "            corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "            return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "        ok, corners = cv2.findChessboardCornersSB(255 - g1, PATTERN_SIZE, SB_FLAGS)\n",
    "        if ok:\n",
    "            corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "            return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Fallback classic detector (less robust), with subpixel refinement.\n",
    "    ok, corners = cv2.findChessboardCorners(g1, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "    if ok:\n",
    "        corners = cv2.cornerSubPix(g1, corners, (11, 11), (-1, -1), term)\n",
    "        corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "        return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    ok, corners = cv2.findChessboardCorners(255 - g1, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "    if ok:\n",
    "        corners = cv2.cornerSubPix(255 - g1, corners, (11, 11), (-1, -1), term)\n",
    "        corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "        return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    return None\n",
    "\n",
    "# ----------------------------\n",
    "# Corner tracking (LK) + gating + smoothing + robust homography\n",
    "# ----------------------------\n",
    "# This is the part that prevents:\n",
    "#   - “collapse to middle then expand”\n",
    "#   - “one frame shoots corners far away”\n",
    "#   - jitter from small frame-to-frame corner noise\n",
    "#\n",
    "# Approach:\n",
    "#   * If we already have corners, track them frame-to-frame with LK.\n",
    "#   * Validate tracks with forward-backward consistency + max jump.\n",
    "#   * If too many corners are bad, declare tracking failed and re-detect (if enabled).\n",
    "#   * Smooth accepted corners with EMA.\n",
    "#   * Fit homography with RANSAC and invert it (image -> world).\n",
    "\n",
    "N_CORNERS = int(PATTERN_SIZE[0] * PATTERN_SIZE[1])\n",
    "MIN_GOOD_COUNT = int(np.ceil(float(TRACK_MIN_FRAC) * N_CORNERS))\n",
    "\n",
    "LK_WIN = (21, 21)\n",
    "LK_MAX_LEVEL = 3\n",
    "LK_CRIT = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)\n",
    "\n",
    "FB_ERR_MAX_PX = 1.25   # forward-backward error threshold (pixels)\n",
    "MAX_JUMP_PX = 30.0     # max per-corner displacement per frame (pixels)\n",
    "\n",
    "def ema_corners(prev_smooth, new_corners, alpha):\n",
    "    # EMA in coordinate space; preserves corner ordering and reduces jitter.\n",
    "    if prev_smooth is None:\n",
    "        return new_corners.copy()\n",
    "    a = float(alpha)\n",
    "    return ((1.0 - a) * prev_smooth + a * new_corners).astype(np.float32)\n",
    "\n",
    "def track_corners_robust(prev_gray, gray, corners_prev):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      corners_next (N,1,2) float32  OR  None if tracking is considered failed\n",
    "      good_mask    (N,) bool\n",
    "    \"\"\"\n",
    "    p0 = corners_prev.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Forward track: prev -> curr\n",
    "    p1, st1, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        prev_gray, gray, p0, None,\n",
    "        winSize=LK_WIN, maxLevel=LK_MAX_LEVEL, criteria=LK_CRIT,\n",
    "        flags=0, minEigThreshold=1e-4\n",
    "    )\n",
    "    if p1 is None or st1 is None:\n",
    "        return None, None\n",
    "\n",
    "    # Backward track: curr -> prev (for forward-backward check)\n",
    "    p0b, st2, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        gray, prev_gray, p1, None,\n",
    "        winSize=LK_WIN, maxLevel=LK_MAX_LEVEL, criteria=LK_CRIT,\n",
    "        flags=0, minEigThreshold=1e-4\n",
    "    )\n",
    "    if p0b is None or st2 is None:\n",
    "        return None, None\n",
    "\n",
    "    st1 = st1.reshape(-1).astype(bool)\n",
    "    st2 = st2.reshape(-1).astype(bool)\n",
    "\n",
    "    p0_xy = p0.reshape(-1, 2)\n",
    "    p1_xy = p1.reshape(-1, 2)\n",
    "    p0b_xy = p0b.reshape(-1, 2)\n",
    "\n",
    "    fb_err = np.linalg.norm(p0_xy - p0b_xy, axis=1)       # how consistent is the track?\n",
    "    disp = np.linalg.norm(p1_xy - p0_xy, axis=1)          # how far did it move this frame?\n",
    "\n",
    "    good = st1 & st2 & (fb_err <= float(FB_ERR_MAX_PX)) & (disp <= float(MAX_JUMP_PX))\n",
    "    good_n = int(good.sum())\n",
    "\n",
    "    # Not enough reliable points -> treat as failed tracking\n",
    "    if good_n < MIN_GOOD_COUNT:\n",
    "        return None, good\n",
    "\n",
    "    # Preserve ordering: any “bad” corner stays at previous location instead of poisoning H\n",
    "    p1_fix = p1.copy()\n",
    "    if (~good).any():\n",
    "        p1_fix.reshape(-1, 2)[~good] = p0_xy[~good]\n",
    "\n",
    "    return p1_fix.astype(np.float32), good\n",
    "\n",
    "def update_hinv_from_corners(corners_full):\n",
    "    \"\"\"\n",
    "    Computes H(world->image) with RANSAC, then stores Hinv(image->world).\n",
    "    RANSAC prevents a small number of remaining bad points from collapsing H.\n",
    "    \"\"\"\n",
    "    global _have_H, _Hinv\n",
    "\n",
    "    if corners_full is None:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    img_pts = corners_full.reshape(-1, 2).astype(np.float32)\n",
    "\n",
    "    H_world_to_img, inliers = cv2.findHomography(\n",
    "        world_xy, img_pts, method=cv2.RANSAC, ransacReprojThreshold=2.0\n",
    "    )\n",
    "    if H_world_to_img is None or inliers is None:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    # Require enough inliers to trust the pose\n",
    "    if int(inliers.sum()) < MIN_GOOD_COUNT:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        _Hinv = np.linalg.inv(H_world_to_img)\n",
    "    except np.linalg.LinAlgError:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    _have_H = True\n",
    "\n",
    "# ----------------------------\n",
    "# Main loop\n",
    "# ----------------------------\n",
    "print(\"ESC=quit | C=clear | P=print | RClick toggle zoom\")\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok or frame is None:\n",
    "        break\n",
    "\n",
    "    # (1) Undistort\n",
    "    h, w = frame.shape[:2]\n",
    "    if newK is None or last_size != (w, h):\n",
    "        # newK is a per-resolution projection that makes undistortion stable (cached)\n",
    "        newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), 1)\n",
    "        last_size = (w, h)\n",
    "\n",
    "    und = cv2.undistort(frame, K, dist, None, newK)\n",
    "    gray = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # (2) Update board pose:\n",
    "    #     - re-detect periodically (anchors)\n",
    "    #     - otherwise track from previous frame (stability)\n",
    "    need_detect = (_corners_full is None) or ((_frame_i % DETECT_EVERY_N) == 0)\n",
    "\n",
    "    if not need_detect and _prev_gray is not None and _corners_full is not None:\n",
    "        tracked_corners, good_mask = track_corners_robust(_prev_gray, gray, _corners_full)\n",
    "\n",
    "        if tracked_corners is None:\n",
    "            # Tracking failed hard (too many bad corners)\n",
    "            if REDETECT_ON_TRACK_FAIL:\n",
    "                need_detect = True\n",
    "            else:\n",
    "                _have_H = False\n",
    "                _Hinv = None\n",
    "        else:\n",
    "            # Tracking succeeded -> smooth -> update homography\n",
    "            _corners_full = tracked_corners\n",
    "            _corners_smooth = ema_corners(_corners_smooth, _corners_full, CORNER_EMA_ALPHA)\n",
    "            update_hinv_from_corners(_corners_smooth)\n",
    "\n",
    "    if need_detect:\n",
    "        detected = detect_board_fast(gray)\n",
    "        if detected is not None:\n",
    "            _corners_full = detected\n",
    "            _corners_smooth = ema_corners(_corners_smooth, _corners_full, CORNER_EMA_ALPHA)\n",
    "            update_hinv_from_corners(_corners_smooth)\n",
    "        else:\n",
    "            _have_H = False\n",
    "            _Hinv = None\n",
    "\n",
    "    # Store current gray for next frame’s tracking\n",
    "    _prev_gray = gray\n",
    "\n",
    "    # (3) Display image (scaled), but keep all point math in full-res coords\n",
    "    disp_scale = compute_display_scale(und.shape[0], und.shape[1])\n",
    "    disp = und if disp_scale >= 1.0 else cv2.resize(\n",
    "        und,\n",
    "        (int(und.shape[1] * disp_scale), int(und.shape[0] * disp_scale)),\n",
    "        interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "\n",
    "    # Draw detected corners (use smoothed corners to avoid visible jitter)\n",
    "    corners_for_draw = _corners_smooth if _corners_smooth is not None else _corners_full\n",
    "    if corners_for_draw is not None:\n",
    "        corners_disp = corners_for_draw.copy()\n",
    "        corners_disp[:, 0, 0] *= disp_scale\n",
    "        corners_disp[:, 0, 1] *= disp_scale\n",
    "        cv2.drawChessboardCorners(disp, PATTERN_SIZE, corners_disp, True)\n",
    "\n",
    "    # (4) Draw clicked points + quad; compute metric dims if homography is valid\n",
    "    if len(pts) > 0:\n",
    "        for i, (x, y) in enumerate(pts):\n",
    "            dx, dy = to_disp(x, y, disp_scale)\n",
    "            draw_marker(disp, dx, dy)\n",
    "            cv2.putText(\n",
    "                disp, str(i + 1),\n",
    "                (dx + POINT_RING_R + 4, dy - POINT_RING_R - 2),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, LABEL_SCALE, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            quad = order_quad(pts)\n",
    "            quad_disp = (quad * disp_scale).astype(np.float32)\n",
    "            cv2.polylines(\n",
    "                disp, [quad_disp.astype(np.int32).reshape(-1, 1, 2)],\n",
    "                True, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            if _have_H and _Hinv is not None:\n",
    "                pts_img = quad.astype(np.float32).reshape(-1, 1, 2)\n",
    "                # perspectiveTransform expects image points; Hinv maps image->world (board plane meters)\n",
    "                pts_world = cv2.perspectiveTransform(pts_img, _Hinv).reshape(-1, 2)\n",
    "                w_m, h_m = quad_wh_m(pts_world)\n",
    "                last_dims_m = (float(w_m), float(h_m))\n",
    "\n",
    "    # (5) Status overlay\n",
    "    status = [\n",
    "        f\"board: {'OK' if _have_H else 'NOT FOUND'} | points: {len(pts)}/4 | zoom: {'ON' if zoom_on else 'OFF'}\"\n",
    "    ]\n",
    "    if last_dims_m is not None:\n",
    "        status.append(f\"W: {last_dims_m[0] * 1000.0:.1f} mm   H: {last_dims_m[1] * 1000.0:.1f} mm\")\n",
    "    else:\n",
    "        status.append(\"W: --   H: --\")\n",
    "\n",
    "    draw_text(disp, status)\n",
    "    cv2.imshow(main_win, disp)\n",
    "\n",
    "    # (6) Zoom window\n",
    "    if zoom_on:\n",
    "        if zoom_center is None:\n",
    "            zoom_center = (w // 2, h // 2)\n",
    "\n",
    "        zoom_img, origin = make_zoom_view(und, zoom_center, zoom_radius, zoom_factor)\n",
    "        _last_zoom_origin = origin\n",
    "\n",
    "        if zoom_img is not None and origin is not None:\n",
    "            ox, oy = origin\n",
    "\n",
    "            for i, (px, py) in enumerate(pts):\n",
    "                zx = int((px - ox) * zoom_factor)\n",
    "                zy = int((py - oy) * zoom_factor)\n",
    "                if 0 <= zx < zoom_img.shape[1] and 0 <= zy < zoom_img.shape[0]:\n",
    "                    draw_marker(zoom_img, zx, zy)\n",
    "                    cv2.putText(\n",
    "                        zoom_img, str(i + 1),\n",
    "                        (zx + POINT_RING_R + 4, zy - POINT_RING_R - 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, LABEL_SCALE, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "            cv2.imshow(zoom_win, zoom_img)\n",
    "\n",
    "    # (7) Key handling\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key in (ord('c'), ord('C')):\n",
    "        pts = []\n",
    "        drag_i = None\n",
    "        cycle_i = 0\n",
    "        last_dims_m = None\n",
    "    if key in (ord('p'), ord('P')):\n",
    "        if last_dims_m is None:\n",
    "            print(\"No measurement yet (need 4 points + board found).\")\n",
    "        else:\n",
    "            print(f\"W: {last_dims_m[0] * 1000.0:.1f} mm | H: {last_dims_m[1] * 1000.0:.1f} mm\")\n",
    "\n",
    "    _frame_i += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if last_dims_m is None:\n",
    "    raise RuntimeError(\"No measurement captured (need 4 clicked points + board found).\")\n",
    "\n",
    "print(\"Measured dimensions:\")\n",
    "print(f\"  Width : {last_dims_m[0] * 1000.0:.1f} mm\")\n",
    "print(f\"  Height: {last_dims_m[1] * 1000.0:.1f} mm\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

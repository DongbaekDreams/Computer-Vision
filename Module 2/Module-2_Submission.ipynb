{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ca39a7",
   "metadata": {},
   "source": [
    "\n",
    "# README (COMMON) — Camera calibration + live measurement (Chessboard, phone stream or webcam)\n",
    "\n",
    "## What this notebook does.\n",
    "This notebook is split into 4 code “blocks” (cells) that together let you:\n",
    "1) Open a phone MJPEG stream (or webcam fallback)\n",
    "2) Optionally capture calibration frames\n",
    "3) Calibrate (or load) camera intrinsics (K, dist)\n",
    "4) Optionally sanity-check undistortion (side-by-side mosaic)\n",
    "5) Run a live measurement tool that maps 4 clicked image points onto the chessboard plane (meters) and reports width/height (mm)\n",
    "\n",
    "## Requirements\n",
    "- Python 3.x\n",
    "- Packages:\n",
    "  - `opencv-python`\n",
    "  - `numpy`\n",
    "\n",
    "## Files / outputs\n",
    "- `calib_frames_phone/` (folder): saved calibration images if you capture frames\n",
    "- `camera_intrinsics_phone.npz` (file): saved intrinsics (K, dist, image_size, metadata)\n",
    "\n",
    "## Chessboard assumptions\n",
    "- Board is 8×8 squares → **7×7 inner corners**: `PATTERN_SIZE = (7, 7)`\n",
    "- Square size is derived from `BOARD_OUTER_MM / 8` → `SQUARE_MM`\n",
    "- Units:\n",
    "  - Calibration object points are in **meters**\n",
    "  - Live measurement prints **mm**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d91bc",
   "metadata": {},
   "source": [
    "## How to run (typical workflows)\n",
    "\n",
    "### Workflow A (already calibrated)\n",
    "1) **Block 1**: leave defaults; ensure `INTRINSICS_PATH` exists.\n",
    "2) **Block 2**: keep `PRE_CALIBRATED=True` (loads intrinsics)\n",
    "3) (Optional) **Block 3**: set `SHOW_COMPARISON=True` to sanity-check undistortion\n",
    "4) **Block 4**: run live measurement and click 4 points to measure\n",
    "\n",
    "### Workflow B (calibrate from scratch)\n",
    "1) **Block 1**: set `PRE_CALIBRATED=False` and verify:\n",
    "   - `CAM_BASE` points to your phone-stream control page\n",
    "   - `PATTERN_SIZE`, `BOARD_OUTER_MM` match your printed board\n",
    "2) **Block 2**(A): capture ~15–30 frames with varied angles/distances (SPACE to save)\n",
    "3) **Block 2**(B): calibrate; saves `camera_intrinsics_phone.npz`\n",
    "4) (Optional) **Block 3**: sanity-check undistortion\n",
    "5) **Block 4**: run live measurement\n",
    "\n",
    "## Controls (reused across relevant blocks)\n",
    "- ESC: quit\n",
    "- Block 2 capture: SPACE save frame\n",
    "- Block 4 measurement:\n",
    "  - Left-click: add / drag points\n",
    "  - Right-click: toggle zoom window\n",
    "  - C: clear points\n",
    "  - P: print last measurement to console\n",
    "\n",
    "## Troubleshooting quick hits\n",
    "- **Phone page opens in browser, but OpenCV can’t read stream**:\n",
    "  - Open `CAM_BASE` in browser → right-click video → copy “video address”\n",
    "  - Set `CAM_BASE` to that direct stream URL or extend `COMMON_STREAM_PATHS`\n",
    "- **No chessboard detections**:\n",
    "  - Improve lighting, reduce glare, fill more of frame, add angles\n",
    "  - Enable `CLAHE_ON=True` (already in your config)\n",
    "- **Live measurement says board NOT FOUND**:\n",
    "  - Move board to be more fronto-parallel, improve contrast\n",
    "  - Wait for periodic re-detection (`DETECT_EVERY_N`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b0938",
   "metadata": {},
   "source": [
    "# Block 1 — Shared config + helpers (used by all cells)\n",
    "\n",
    "## Purpose\n",
    "Defines all shared configuration and helper functions used by later blocks:\n",
    "- Chessboard geometry (square size, inner-corner pattern)\n",
    "- Phone stream discovery helpers that scrape `CAM_BASE` and try common MJPEG endpoints\n",
    "- Object-point generator for calibration (`mk_object_points`)\n",
    "\n",
    "## Key settings to change\n",
    "- `PRE_CALIBRATED`:\n",
    "  - `True`: skip capture + calibration; load `camera_intrinsics_phone.npz`\n",
    "  - `False`: capture and calibrate from images in `calib_frames_phone/`\n",
    "- `SHOW_COMPARISON`:\n",
    "  - `True`: enable Block 3 undistortion mosaic\n",
    "- `CAM_BASE`: base page for your phone stream (IP Webcam / DroidCam-like servers)\n",
    "- `BOARD_OUTER_MM`, `PATTERN_SIZE`:\n",
    "  - Must match your printed chessboard\n",
    "  - 8×8 squares → `PATTERN_SIZE=(7,7)`\n",
    "- Output paths:\n",
    "  - `CALIB_DIR` folder for captured frames\n",
    "  - `INTRINSICS_PATH` for saved intrinsics `.npz`\n",
    "\n",
    "## What it provides to downstream blocks\n",
    "- `open_phone_cap()` → returns `(cap, chosen_url, first_frame)`\n",
    "- `mk_object_points(pattern_size, square_m)` → 3D chessboard corner points in meters\n",
    "\n",
    "## Notes / assumptions\n",
    "- Stream endpoint discovery is best-effort:\n",
    "  - It scrapes HTML for `href/src` URLs containing common MJPEG keywords\n",
    "  - It tries `COMMON_STREAM_PATHS` fallbacks\n",
    "- If none work, it raises an error telling you how to copy the direct stream URL from the browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# TOP CELL — Shared config + helpers (used by all cells below)\n",
    "# ============================\n",
    "# This cell defines:\n",
    "#   1) Global configuration (toggles, board geometry, capture/display parameters)\n",
    "#   2) Phone-stream URL discovery helpers (so OpenCV can open the MJPEG stream)\n",
    "#   3) Calibration helper to build chessboard 3D object points\n",
    "#\n",
    "# Design intent:\n",
    "#   - All other notebook cells read variables and call helpers defined here.\n",
    "#   - Keep “knobs” (constants/toggles) grouped and well-labeled so behavior is easy to audit.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Notebook toggles\n",
    "# ----------------------------\n",
    "# PRE_CALIBRATED:\n",
    "#   True  -> later cells load intrinsics from INTRINSICS_PATH\n",
    "#   False -> later cells capture frames + calibrate intrinsics\n",
    "PRE_CALIBRATED = True\n",
    "\n",
    "# SHOW_COMPARISON:\n",
    "#   Used by the undistortion sanity-check cell (side-by-side view)\n",
    "SHOW_COMPARISON = True\n",
    "\n",
    "# ----------------------------\n",
    "# Board geometry (used for calibration + measurement)\n",
    "# ----------------------------\n",
    "# BOARD_OUTER_MM:\n",
    "#   Physical outer width/height of the printed board (mm). Used to derive square size.\n",
    "#\n",
    "# 8x8 squares => 7x7 inner corners (PATTERN_SIZE).\n",
    "BOARD_OUTER_MM = 336.0\n",
    "SQUARE_MM = BOARD_OUTER_MM / 8.0          # mm per square (derived)\n",
    "SQUARE_M = SQUARE_MM / 1000.0             # meters per square (calibration scale)\n",
    "PATTERN_SIZE = (7, 7)                     # inner corners: (cols, rows)\n",
    "\n",
    "# ----------------------------\n",
    "# Phone stream base page\n",
    "# ----------------------------\n",
    "# CAM_BASE:\n",
    "#   The base “control page” URL that you can open in a browser.\n",
    "#   The helper open_phone_cap() will scrape/guess likely MJPEG endpoints from this page.\n",
    "CAM_BASE = \"http://192.168.1.70:8080/\"  # must be reachable from the laptop running OpenCV\n",
    "\n",
    "# ----------------------------\n",
    "# File locations\n",
    "# ----------------------------\n",
    "# CALIB_DIR:\n",
    "#   Where captured calibration frames are saved (JPEG).\n",
    "#\n",
    "# INTRINSICS_PATH:\n",
    "#   Where calibration results are saved/loaded (npz).\n",
    "CALIB_DIR = Path(\"calib_frames_phone\")\n",
    "INTRINSICS_PATH = \"camera_intrinsics_phone.npz\"\n",
    "\n",
    "# ----------------------------\n",
    "# Capture preview sizing (UI only)\n",
    "# ----------------------------\n",
    "# Preview is downscaled to fit your screen; saved frames remain full-resolution.\n",
    "PREVIEW_MAX_W = 1600\n",
    "PREVIEW_MAX_H = 900\n",
    "\n",
    "# ----------------------------\n",
    "# Stream endpoint discovery\n",
    "# ----------------------------\n",
    "# COMMON_STREAM_PATHS:\n",
    "#   Fallback MJPEG endpoints commonly used by phone IP webcam apps.\n",
    "#   open_phone_cap() tries scraped endpoints first, then these fallbacks.\n",
    "COMMON_STREAM_PATHS = [\n",
    "    \"video\",\n",
    "    \"videofeed\",\n",
    "    \"mjpeg\", \"mjpegfeed\",\n",
    "    \"live\", \"stream\",\n",
    "    \"?action=stream\",\n",
    "    \"video?x.mjpeg\",\n",
    "    \"mjpg/video.mjpg\",\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Live measurement config (read by measurement cell)\n",
    "# ----------------------------\n",
    "# Camera selection:\n",
    "#   CAM_INDEX is used for a local webcam fallback (if the measurement cell supports it).\n",
    "CAM_INDEX = 0\n",
    "\n",
    "# Capture resolution request (best-effort; the device may clamp to supported modes).\n",
    "CAPTURE_W = 3840\n",
    "CAPTURE_H = 2160\n",
    "\n",
    "# Detection cadence / preprocess\n",
    "# DETECT_EVERY_N:\n",
    "#   Run the full chessboard detector every N frames (intermediate frames rely on tracking).\n",
    "DETECT_EVERY_N = 12\n",
    "\n",
    "# DETECT_SCALE:\n",
    "#   Downscale factor for detection to improve speed (tracking may still run on full-res).\n",
    "DETECT_SCALE = 0.45\n",
    "\n",
    "# CLAHE_ON:\n",
    "#   Enable CLAHE contrast boost before detection (helps under uneven lighting/glare).\n",
    "CLAHE_ON = True\n",
    "\n",
    "# SB_FIRST:\n",
    "#   Try findChessboardCornersSB first (often more robust than classic).\n",
    "SB_FIRST = True\n",
    "\n",
    "# Tracking / smoothing\n",
    "# TRACK_MIN_FRAC:\n",
    "#   Minimum fraction of corners that must successfully track to accept the tracked result.\n",
    "TRACK_MIN_FRAC = 0.75\n",
    "\n",
    "# CORNER_EMA_ALPHA:\n",
    "#   Exponential moving average alpha for stabilizing corner coordinates (reduces jitter).\n",
    "CORNER_EMA_ALPHA = 0.20\n",
    "\n",
    "# REDETECT_ON_TRACK_FAIL:\n",
    "#   If tracking fails safety checks, force a full redetection next cycle.\n",
    "REDETECT_ON_TRACK_FAIL = True\n",
    "\n",
    "# LK tracking safety rails (prevents collapse / shoot-off)\n",
    "# FB_ERR_MAX_PX:\n",
    "#   Max allowable forward-backward error (px) for Lucas-Kanade tracking.\n",
    "FB_ERR_MAX_PX = 1.25\n",
    "\n",
    "# MAX_JUMP_PX:\n",
    "#   Max allowable per-corner jump (px) between frames.\n",
    "MAX_JUMP_PX = 30.0\n",
    "\n",
    "# Display sizing (UI only)\n",
    "DISPLAY_MAX_W = 1600\n",
    "DISPLAY_MAX_H = 900\n",
    "\n",
    "# Point rendering (UI only)\n",
    "POINT_RING_R = 8\n",
    "POINT_RING_TH = 2\n",
    "POINT_CENTER_R = 1\n",
    "POINT_HIT_R_FULL = 12\n",
    "LABEL_SCALE = 0.6\n",
    "\n",
    "# Zoom window parameters (UI only)\n",
    "zoom_factor = 4\n",
    "zoom_radius = 180\n",
    "zoom_win = \"zoom\"\n",
    "\n",
    "# ----------------------------\n",
    "# URL discovery helpers\n",
    "# ----------------------------\n",
    "def _fetch_html(url, timeout=3.0):\n",
    "    \"\"\"\n",
    "    Fetch HTML from CAM_BASE using a browser-like User-Agent.\n",
    "    This is used to scrape candidate MJPEG/video endpoints from the control page.\n",
    "    \"\"\"\n",
    "    req = urllib.request.Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    with urllib.request.urlopen(req, timeout=timeout) as r:\n",
    "        return r.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def _extract_stream_urls_from_html(base_url, html):\n",
    "    \"\"\"\n",
    "    Parse href/src attributes and keep only URLs that look like video/MJPEG endpoints.\n",
    "    Returns absolute URLs joined against base_url.\n",
    "    \"\"\"\n",
    "    candidates = set()\n",
    "    for m in re.finditer(r'(?:href|src)\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, flags=re.IGNORECASE):\n",
    "        u = m.group(1).strip()\n",
    "        if not u:\n",
    "            continue\n",
    "        low = u.lower()\n",
    "        if any(k in low for k in [\"mjpeg\", \"mjpg\", \"videofeed\", \"video\", \"stream\", \"action=stream\"]):\n",
    "            candidates.add(urllib.parse.urljoin(base_url, u))\n",
    "    return list(candidates)\n",
    "\n",
    "def _try_open_url(url):\n",
    "    \"\"\"\n",
    "    Attempt to open a URL with OpenCV using a small set of backends.\n",
    "    Returns (cap, first_frame) on success, else (None, None).\n",
    "    \"\"\"\n",
    "    backends = [None, cv2.CAP_MSMF]\n",
    "    try:\n",
    "        backends.append(cv2.CAP_FFMPEG)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    for be in backends:\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(url) if be is None else cv2.VideoCapture(url, be)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if cap is None or not cap.isOpened():\n",
    "            try:\n",
    "                cap.release()\n",
    "            except:\n",
    "                pass\n",
    "            continue\n",
    "\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None and frame.size > 0:\n",
    "            return cap, frame\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def open_phone_cap():\n",
    "    \"\"\"\n",
    "    Open a phone MJPEG stream by:\n",
    "      1) fetching CAM_BASE HTML and scraping likely stream URLs\n",
    "      2) falling back to COMMON_STREAM_PATHS if scraping finds nothing usable\n",
    "      3) trying each candidate until OpenCV returns a valid first frame\n",
    "\n",
    "    Returns:\n",
    "      cap         : cv2.VideoCapture already opened\n",
    "      chosen_url  : the URL that worked\n",
    "      first_frame : first successfully read frame (used for sizing sanity checks)\n",
    "    \"\"\"\n",
    "    base = CAM_BASE if CAM_BASE.endswith(\"/\") else (CAM_BASE + \"/\")\n",
    "\n",
    "    # Scrape the control page for embedded stream URLs\n",
    "    html = _fetch_html(base, timeout=3.0)\n",
    "    scraped = _extract_stream_urls_from_html(base, html)\n",
    "\n",
    "    # Add common fallback endpoints (joined against CAM_BASE)\n",
    "    fallbacks = [urllib.parse.urljoin(base, p) for p in COMMON_STREAM_PATHS]\n",
    "\n",
    "    # De-duplicate while preserving order (scraped first, then fallbacks)\n",
    "    seen = set()\n",
    "    candidates = []\n",
    "    for u in scraped + fallbacks:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            candidates.append(u)\n",
    "\n",
    "    # Try opening each candidate until one yields valid frames\n",
    "    for u in candidates:\n",
    "        cap, frame = _try_open_url(u)\n",
    "        if cap is not None:\n",
    "            return cap, u, frame\n",
    "\n",
    "    # If the browser can show video but OpenCV can't, user likely needs the direct MJPEG URL.\n",
    "    raise RuntimeError(\n",
    "        \"Browser opens CAM_BASE, but OpenCV can't find a readable stream endpoint.\\n\"\n",
    "        \"Fix:\\n\"\n",
    "        \"  - Open CAM_BASE in your browser\\n\"\n",
    "        \"  - Right-click the video -> Copy video address\\n\"\n",
    "        \"  - Set CAM_BASE to that direct stream URL (or paste it here)\\n\"\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# Calibration helper\n",
    "# ----------------------------\n",
    "def mk_object_points(pattern_size, square_m):\n",
    "    \"\"\"\n",
    "    Build the canonical 3D corner coordinates for a planar chessboard (Z=0).\n",
    "    The returned array is paired with detected 2D corners to calibrate the camera.\n",
    "\n",
    "    pattern_size: (nx, ny) inner corners, e.g. (7,7) for an 8x8 square board\n",
    "    square_m    : physical square size in meters\n",
    "    \"\"\"\n",
    "    nx, ny = pattern_size\n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2) * square_m\n",
    "    return objp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957896c",
   "metadata": {},
   "source": [
    "# Block 2 — Capture frames + Calibrate (or load) intrinsics\n",
    "\n",
    "## Purpose\n",
    "Two-part block:\n",
    "(A) Capture calibration frames from the phone stream into `CALIB_DIR` (only if `PRE_CALIBRATED=False`)\n",
    "(B) Either load intrinsics from `INTRINSICS_PATH` (if `PRE_CALIBRATED=True`) or calibrate from saved frames and save intrinsics\n",
    "\n",
    "## How to execute\n",
    "- If you already have `camera_intrinsics_phone.npz`:\n",
    "  - Set `PRE_CALIBRATED=True`\n",
    "  - Run Block 2 → it loads `K`, `dist`, `image_size`\n",
    "- If you need to calibrate:\n",
    "  - Set `PRE_CALIBRATED=False`\n",
    "  - Run Block 2:\n",
    "    - Part (A): press SPACE to save multiple frames (15–30 recommended), ESC to quit capture\n",
    "    - Part (B): runs chessboard detection on saved `.jpg` frames and calibrates\n",
    "\n",
    "## Output\n",
    "- When calibrating: writes `camera_intrinsics_phone.npz` with:\n",
    "  - `camera_matrix` (K), `dist_coeffs` (dist), `image_size`\n",
    "  - metadata: `pattern_size`, `square_length_m`, `board_outer_mm`, `cam_base`, `rms`\n",
    "\n",
    "## Detection details (what it tries)\n",
    "- Preprocess: CLAHE (contrast boost)\n",
    "- Primary detector: `cv2.findChessboardCornersSB` on normal and inverted images\n",
    "- Fallback: classic `findChessboardCorners` + `cornerSubPix`\n",
    "\n",
    "## Common failure modes\n",
    "- “No images found”: you didn’t capture frames or `CALIB_DIR` path is wrong\n",
    "- “No usable chessboard detections”:\n",
    "  - improve lighting, reduce glare, include more tilt/rotation, fill frame more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened stream: http://192.168.1.70:8080/video\n",
      "Stream resolution: 1920x1080\n",
      "SPACE=save | ESC=quit\n",
      "ESC pressed; exiting.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     98\u001b[39m g = clahe.apply(gray)\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Preferred: findChessboardCornersSB (robust) on normal and inverted.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m ok, corners = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindChessboardCornersSB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATTERN_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSB_FLAGS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[32m    103\u001b[39m     ok, corners = cv2.findChessboardCornersSB(\u001b[32m255\u001b[39m - g, PATTERN_SIZE, SB_FLAGS)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CAPTURE (optional) + CALIBRATE/LOAD INTRINSICS\n",
    "# ============================================================\n",
    "# This cell is self-contained:\n",
    "#   - If PRE_CALIBRATED is False: optionally capture frames from the phone stream, then calibrate from them.\n",
    "#   - If PRE_CALIBRATED is True : skip capture + detection and load intrinsics from INTRINSICS_PATH.\n",
    "#\n",
    "# Key idea:\n",
    "#   Calibration estimates camera intrinsics:\n",
    "#     - K    : camera matrix (focal lengths + principal point)\n",
    "#     - dist : lens distortion coefficients\n",
    "#   These are required for accurate undistortion and any measurement on the image plane.\n",
    "#\n",
    "# Chessboard conventions:\n",
    "#   - PATTERN_SIZE is the number of INNER corners (cols, rows).\n",
    "#   - SQUARE_M is the physical square size in meters (sets real-world scale).\n",
    "#   - All calibration images must share the same resolution (enforced below).\n",
    "\n",
    "# ----------------------------\n",
    "# (A) Capture frames (optional)\n",
    "# ----------------------------\n",
    "# Captures full-res frames from the phone stream into CALIB_DIR.\n",
    "# Preview is mirrored and downscaled only for usability; saved images remain the original frames.\n",
    "if not PRE_CALIBRATED:\n",
    "    # Ensure output directory exists (e.g., ./calib_frames_phone/)\n",
    "    CALIB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Connect to the phone stream and confirm we can read frames\n",
    "    cap, chosen_url, first = open_phone_cap()\n",
    "    h0, w0 = first.shape[:2]\n",
    "    print(\"Opened stream:\", chosen_url)\n",
    "    print(f\"Stream resolution: {w0}x{h0}\")\n",
    "    print(\"SPACE=save | ESC=quit\")\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            # Stream stalled/disconnected (avoid an infinite loop)\n",
    "            print(\"Frame read failed; exiting.\")\n",
    "            break\n",
    "\n",
    "        # Mirror preview so on-screen motion feels intuitive.\n",
    "        # (Saved frames are NOT mirrored.)\n",
    "        preview = cv2.flip(frame, 1)\n",
    "\n",
    "        # Fit preview to a maximum window size without changing aspect ratio.\n",
    "        ph, pw = preview.shape[:2]\n",
    "        scale = min(PREVIEW_MAX_W / pw, PREVIEW_MAX_H / ph, 1.0)\n",
    "        if scale < 1.0:\n",
    "            preview = cv2.resize(\n",
    "                preview,\n",
    "                (int(pw * scale), int(ph * scale)),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"PHONE: SPACE=save | ESC=quit\", preview)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 27:  # ESC\n",
    "            print(\"ESC pressed; exiting.\")\n",
    "            break\n",
    "\n",
    "        if key == 32:  # SPACE\n",
    "            # Save the full-resolution original frame (not mirrored, not downscaled).\n",
    "            fname = CALIB_DIR / f\"frame_{idx:04d}.jpg\"\n",
    "            ok_write = cv2.imwrite(\n",
    "                str(fname),\n",
    "                frame,\n",
    "                [int(cv2.IMWRITE_JPEG_QUALITY), 95]\n",
    "            )\n",
    "            print(f\"Saved {fname}\" if ok_write else f\"Failed to save {fname}\")\n",
    "            idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    # When PRE_CALIBRATED=True, the cell uses INTRINSICS_PATH instead of capturing frames.\n",
    "    print(\"Skipping capture (PRE_CALIBRATED=True)\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# (B) Calibrate or load intrinsics\n",
    "# ----------------------------\n",
    "# This section produces:\n",
    "#   - K (camera_matrix), dist (dist_coeffs), and image_size (width, height).\n",
    "# It either loads these from disk (PRE_CALIBRATED=True) or computes them from images in CALIB_DIR.\n",
    "if PRE_CALIBRATED:\n",
    "    # Load intrinsics saved by this same notebook (np.savez)\n",
    "    z = np.load(INTRINSICS_PATH, allow_pickle=True)\n",
    "    K = z[\"camera_matrix\"]\n",
    "    dist = z[\"dist_coeffs\"]\n",
    "    image_size = tuple(z[\"image_size\"])  # (width, height)\n",
    "    print(\"Loaded intrinsics from\", INTRINSICS_PATH)\n",
    "    print(\"image_size:\", image_size)\n",
    "else:\n",
    "    # 3D corner coordinates for the chessboard in its own coordinate system (Z=0 plane).\n",
    "    # These coordinates are paired with detected 2D corners in each image.\n",
    "    objp = mk_object_points(PATTERN_SIZE, SQUARE_M)\n",
    "\n",
    "    objpoints = []  # list of (N,3) 3D points, one entry per successful image\n",
    "    imgpoints = []  # list of (N,1,2) 2D points, one entry per successful image\n",
    "    image_size = None\n",
    "\n",
    "    # Prefer the SB detector (often more robust on phone images).\n",
    "    SB_FLAGS = (cv2.CALIB_CB_EXHAUSTIVE | cv2.CALIB_CB_ACCURACY)\n",
    "\n",
    "    # Classic detector fallback (plus subpixel refinement).\n",
    "    CLASSIC_FLAGS = (cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
    "\n",
    "    # CLAHE can improve local contrast under uneven lighting / mild glare.\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "\n",
    "    # Collect candidate images produced by the capture loop above.\n",
    "    img_files = sorted(glob.glob(str(CALIB_DIR / \"*.jpg\")))\n",
    "    if not img_files:\n",
    "        raise RuntimeError(\n",
    "            f\"No images found in {CALIB_DIR}. \"\n",
    "            \"Set PRE_CALIBRATED=True to load intrinsics, or capture frames first.\"\n",
    "        )\n",
    "\n",
    "    for fname in img_files:\n",
    "        img = cv2.imread(fname)\n",
    "        if img is None:\n",
    "            # Skip unreadable/corrupt files without failing the entire cell\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calibration requires a single consistent resolution across all samples.\n",
    "        if image_size is None:\n",
    "            image_size = (gray.shape[1], gray.shape[0])  # (width, height)\n",
    "\n",
    "        # Contrast-boosted version for detection\n",
    "        g = clahe.apply(gray)\n",
    "\n",
    "        # Try robust SB detection on normal and inverted intensities.\n",
    "        ok, corners = cv2.findChessboardCornersSB(g, PATTERN_SIZE, SB_FLAGS)\n",
    "        if not ok:\n",
    "            ok, corners = cv2.findChessboardCornersSB(255 - g, PATTERN_SIZE, SB_FLAGS)\n",
    "\n",
    "        # Fallback: classic detector + subpixel refinement\n",
    "        if not ok:\n",
    "            ok, corners = cv2.findChessboardCorners(g, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "            if ok:\n",
    "                corners = cv2.cornerSubPix(g, corners, (11, 11), (-1, -1), term)\n",
    "\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        objpoints.append(objp.copy())\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "    n = len(imgpoints)\n",
    "    print(\"chessboard detections:\", n, \"image_size:\", image_size)\n",
    "\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No usable chessboard detections.\\n\"\n",
    "            \"Try: brighter light, less blur, less glare, larger board in frame, varied angles.\"\n",
    "        )\n",
    "\n",
    "    # Estimate intrinsics from all collected correspondences.\n",
    "    rms, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints,\n",
    "        imgpoints,\n",
    "        image_size,\n",
    "        None,\n",
    "        None\n",
    "    )\n",
    "\n",
    "    # Save intrinsics + metadata (useful for assignment reproducibility).\n",
    "    np.savez(\n",
    "        INTRINSICS_PATH,\n",
    "        rms=float(rms),\n",
    "        camera_matrix=K,\n",
    "        dist_coeffs=dist,\n",
    "        image_size=np.array(image_size, dtype=int),\n",
    "        pattern_size=np.array(PATTERN_SIZE, dtype=int),\n",
    "        square_length_m=float(SQUARE_M),\n",
    "        board_outer_mm=float(BOARD_OUTER_MM),\n",
    "        cam_base=str(CAM_BASE),\n",
    "    )\n",
    "\n",
    "    print(\"Saved intrinsics to\", INTRINSICS_PATH)\n",
    "    print(\"RMS reprojection error:\", float(rms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f4925",
   "metadata": {},
   "source": [
    "# Block 3 — Undistortion sanity check (2×2 mosaic)\n",
    "\n",
    "## Purpose\n",
    "Visual diagnostic to verify intrinsics produce sensible undistortion:\n",
    "- RAW frame\n",
    "- UNDISTORTED frame (using `cv2.getOptimalNewCameraMatrix` + `cv2.undistort`)\n",
    "- ABS DIFF (pixel difference magnitude)\n",
    "- HOTSPOTS overlay (regions where undistortion changes pixels a lot)\n",
    "\n",
    "## Preconditions\n",
    "- `SHOW_COMPARISON=True`\n",
    "- `K` and `dist` must already be defined (i.e., Block 2 has been run successfully)\n",
    "\n",
    "## How to execute\n",
    "- Choose source:\n",
    "  - `SOURCE=\"phone_url\"` uses `open_phone_cap()`\n",
    "  - `SOURCE=\"device\"` uses local webcam\n",
    "- ESC to quit\n",
    "\n",
    "## Interpreting output\n",
    "- Some diff/hotspots near edges is normal (lens distortion strongest there)\n",
    "- If hotspots dominate the whole image, intrinsics likely don’t match the actual camera source\n",
    "  - e.g., calibrated on phone but viewing laptop webcam, or vice versa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC=quit | source: phone:http://192.168.1.70:8080/video\n"
     ]
    }
   ],
   "source": [
    "if SHOW_COMPARISON:\n",
    "    # ============================================================\n",
    "    # CALIBRATION SANITY CHECK (LIVE): RAW vs UNDISTORTED + DIFF\n",
    "    # ============================================================\n",
    "    # Purpose:\n",
    "    #   Quick visual verification that (K, dist) match the camera feed you open here.\n",
    "    #   You get a 2x2 mosaic:\n",
    "    #     [ RAW ] [ UNDISTORTED ]\n",
    "    #     [ ABS DIFF (heatmap) ] [ HOTSPOTS overlay ]\n",
    "    #\n",
    "    # Interpretation:\n",
    "    #   - UNDISTORTED should look “straighter” near edges (less barrel/pincushion).\n",
    "    #   - ABS DIFF highlights where pixels changed the most after undistortion.\n",
    "    #   - HOTSPOTS marks pixels whose change exceeded DIFF_THRESH.\n",
    "    #\n",
    "    # Controls:\n",
    "    #   ESC : quit\n",
    "    #\n",
    "    # Assumption:\n",
    "    #   K and dist already exist in the notebook namespace and correspond to the same\n",
    "    #   camera/stream being opened below.\n",
    "\n",
    "    # ----------------------------\n",
    "    # Choose ONE input source\n",
    "    # ----------------------------\n",
    "    # SOURCE:\n",
    "    #   \"phone_url\" -> open the phone MJPEG stream discovered via CAM_BASE\n",
    "    #   \"device\"    -> open a local webcam via DirectShow (Windows)\n",
    "    SOURCE = \"phone_url\"      # \"device\" or \"phone_url\"\n",
    "\n",
    "    # Local webcam settings (used only when SOURCE == \"device\")\n",
    "    CAM_INDEX = 0\n",
    "    CAPTURE_W = 3840\n",
    "    CAPTURE_H = 2160\n",
    "\n",
    "    # Phone stream base page (used only when SOURCE == \"phone_url\")\n",
    "    # Keep this assignment to emphasize this cell uses the top-cell CAM_BASE unless changed.\n",
    "    CAM_BASE = CAM_BASE\n",
    "\n",
    "    # ----------------------------\n",
    "    # Mosaic display layout\n",
    "    # ----------------------------\n",
    "    # Each tile is resized to TILE_W x TILE_H for a stable 2x2 grid.\n",
    "    TILE_W = 640\n",
    "    TILE_H = 360\n",
    "\n",
    "    # ----------------------------\n",
    "    # Diff / hotspot parameters\n",
    "    # ----------------------------\n",
    "    # DIFF_THRESH:\n",
    "    #   Per-pixel threshold (0..255) applied to abs(raw_gray - und_gray) to define hotspots.\n",
    "    DIFF_THRESH = 25\n",
    "\n",
    "    # BLUR_K:\n",
    "    #   Optional Gaussian blur kernel size for the diff image to reduce speckle.\n",
    "    #   Use an odd integer; if even, it is bumped to the next odd integer.\n",
    "    BLUR_K = 5\n",
    "\n",
    "    # ALPHA_NEWK (for getOptimalNewCameraMatrix):\n",
    "    #   0.0 -> crop to valid pixels (minimize black borders)\n",
    "    #   1.0 -> keep all pixels (may include black borders)\n",
    "    ALPHA_NEWK = 0.0\n",
    "\n",
    "    def open_device_cap():\n",
    "        \"\"\"\n",
    "        Open a local webcam using MJPG at a requested resolution.\n",
    "\n",
    "        Returns:\n",
    "          cap         : cv2.VideoCapture\n",
    "          src_string  : human-readable source label\n",
    "          first_frame : first frame read (for size checks)\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)\n",
    "        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_W)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_H)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            cap.release()\n",
    "            raise RuntimeError(\"Failed to open camera device\")\n",
    "\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            cap.release()\n",
    "            raise RuntimeError(\"Opened device camera but failed to read a frame\")\n",
    "\n",
    "        return cap, f\"device:{CAM_INDEX}\", frame\n",
    "\n",
    "    def resize_tile(img):\n",
    "        \"\"\"Resize an image into a fixed-size mosaic tile (TILE_W x TILE_H).\"\"\"\n",
    "        return cv2.resize(img, (TILE_W, TILE_H), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def label(img, text):\n",
    "        \"\"\"Draw a readable label: white text with a black outline for contrast.\"\"\"\n",
    "        out = img.copy()\n",
    "        cv2.putText(out, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "        cv2.putText(out, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        return out\n",
    "\n",
    "    # ----------------------------\n",
    "    # Open the selected source\n",
    "    # ----------------------------\n",
    "    if SOURCE == \"phone_url\":\n",
    "        cap, chosen_url, first = open_phone_cap()\n",
    "        src = f\"phone:{chosen_url}\"\n",
    "    elif SOURCE == \"device\":\n",
    "        cap, src, first = open_device_cap()\n",
    "    else:\n",
    "        raise ValueError('SOURCE must be \"phone_url\" or \"device\"')\n",
    "\n",
    "    print(\"ESC=quit | source:\", src)\n",
    "\n",
    "    # Cache the \"optimal new camera matrix\" per frame size.\n",
    "    # If resolution changes mid-stream, we recompute newK.\n",
    "    newK = None\n",
    "    last_size = None\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            # End of stream / read failure\n",
    "            break\n",
    "\n",
    "        # ----------------------------\n",
    "        # Undistort using an \"optimal\" new camera matrix (newK)\n",
    "        # ----------------------------\n",
    "        # getOptimalNewCameraMatrix() returns a projection matrix that trades off:\n",
    "        #   - cropping away invalid pixels (alpha=0)\n",
    "        #   - vs keeping all pixels (alpha=1), which can add black borders\n",
    "        h, w = frame.shape[:2]\n",
    "        if newK is None or last_size != (w, h):\n",
    "            newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), ALPHA_NEWK)\n",
    "            last_size = (w, h)\n",
    "\n",
    "        und = cv2.undistort(frame, K, dist, None, newK)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Diff view: magnitude of pixel change due to undistortion\n",
    "        # ----------------------------\n",
    "        g_raw = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        g_und = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        diff = cv2.absdiff(g_raw, g_und)\n",
    "\n",
    "        # Optional blur to reduce speckle before thresholding / visualization.\n",
    "        if BLUR_K and BLUR_K > 0:\n",
    "            k = BLUR_K if (BLUR_K % 2 == 1) else (BLUR_K + 1)\n",
    "            diff = cv2.GaussianBlur(diff, (k, k), 0)\n",
    "\n",
    "        # Heatmap to make spatial patterns obvious at a glance.\n",
    "        diff_color = cv2.applyColorMap(diff, cv2.COLORMAP_TURBO)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Hotspot mask: threshold + cleanup + overlay\n",
    "        # ----------------------------\n",
    "        # mask highlights pixels where the undistortion changed intensity by >= DIFF_THRESH.\n",
    "        mask = (diff >= DIFF_THRESH).astype(np.uint8) * 255\n",
    "\n",
    "        # Morphology removes isolated noise pixels and slightly expands coherent regions.\n",
    "        k5 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k5)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, k5)\n",
    "\n",
    "        # Overlay: blend red into hotspot pixels on top of the undistorted frame.\n",
    "        overlay = und.copy()\n",
    "        m = (mask > 0)\n",
    "\n",
    "        if m.any():\n",
    "            over_f = overlay.astype(np.float32)\n",
    "            red = np.array([0, 0, 255], dtype=np.float32)\n",
    "            over_f[m] = 0.6 * over_f[m] + 0.4 * red\n",
    "            overlay = over_f.astype(np.uint8)\n",
    "\n",
    "        # Percent of pixels flagged (coarse “how much changed” indicator).\n",
    "        hotspot_pct = 100.0 * float(np.count_nonzero(mask)) / float(mask.size)\n",
    "        overlay = label(overlay, f\"hotspots: {hotspot_pct:.2f}%\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # 2x2 mosaic: RAW / UNDISTORTED / ABS DIFF / HOTSPOTS\n",
    "        # ----------------------------\n",
    "        raw_t  = label(resize_tile(frame),      \"RAW\")\n",
    "        und_t  = label(resize_tile(und),        \"UNDISTORTED\")\n",
    "        diff_t = label(resize_tile(diff_color), \"ABS DIFF\")\n",
    "        over_t = label(resize_tile(overlay),    \"HOTSPOTS\")\n",
    "\n",
    "        top = np.hstack([raw_t, und_t])\n",
    "        bot = np.hstack([diff_t, over_t])\n",
    "        mosaic = np.vstack([top, bot])\n",
    "\n",
    "        cv2.imshow(\"Calibration Sanity Check\", mosaic)\n",
    "\n",
    "        if (cv2.waitKey(1) & 0xFF) == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf0153",
   "metadata": {},
   "source": [
    "# Block 4 — Live measurement on chessboard plane (click 4 points → mm)\n",
    "\n",
    "## Purpose\n",
    "Runs an interactive measurement tool:\n",
    "- Opens camera (phone stream first, otherwise webcam)\n",
    "- Undistorts frames using saved intrinsics (`K`, `dist`)\n",
    "- Maintains a stable chessboard pose estimate using:\n",
    "  - periodic full re-detection (anchors)\n",
    "  - LK optical-flow tracking between detections (stability)\n",
    "  - forward-backward + max-jump gating (prevents blowups)\n",
    "  - EMA smoothing of corners (reduces jitter)\n",
    "  - RANSAC homography (robust to a few bad points)\n",
    "- You click 4 points; if the board pose is valid, points are mapped to board-plane meters and width/height reported in mm\n",
    "\n",
    "## Controls\n",
    "- Left-click: add point / drag nearest existing point\n",
    "- Right-click: toggle zoom window (use zoom to place points precisely)\n",
    "- C: clear points\n",
    "- P: print last measurement\n",
    "- ESC: quit\n",
    "\n",
    "## Preconditions\n",
    "- `INTRINSICS_PATH` must exist and correspond to the camera you’re using\n",
    "- Chessboard must be visible enough for detection (`PATTERN_SIZE`, `SQUARE_M` must match the real board)\n",
    "\n",
    "## Output behavior\n",
    "- Overlay shows:\n",
    "  - board: OK / NOT FOUND\n",
    "  - points: N/4\n",
    "  - last measured W/H in mm (once 4 points are set and board pose is valid)\n",
    "- On exit:\n",
    "  - Raises if no measurement captured (no valid board + 4 points)\n",
    "  - Prints final measured width/height (mm)\n",
    "\n",
    "## Common failure modes\n",
    "- board stays NOT FOUND:\n",
    "  - improve contrast, reduce glare, fill more frame, hold steadier\n",
    "  - consider lowering `DETECT_EVERY_N` (more frequent re-detection) or increasing `DETECT_SCALE` (less downscale)\n",
    "- occasional pose “snaps”:\n",
    "  - tighten gating (`FB_ERR_MAX_PX`, `MAX_JUMP_PX`) or increase `TRACK_MIN_FRAC`\n",
    "  - increase smoothing slightly (`CORNER_EMA_ALPHA`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC=quit | C=clear | P=print | RClick toggle zoom | source: phone:http://192.168.1.70:8080/video\n",
      "ESC=quit | C=clear | P=print | RClick toggle zoom\n",
      "Measured dimensions:\n",
      "  Width : 231.3 mm\n",
      "  Height: 93.6 mm\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Purpose\n",
    "# ----------------------------\n",
    "# Live planar measurement using a chessboard as a metric reference plane.\n",
    "# Workflow:\n",
    "#   - Open camera (phone stream if available, else local webcam)\n",
    "#   - Undistort frames using saved intrinsics (K, dist)\n",
    "#   - Maintain a stable chessboard pose (corner set) via periodic detection + LK tracking\n",
    "#   - Fit a robust homography and invert it to map image pixels -> board-plane meters\n",
    "#   - Click 4 points; when pose is valid, map those points to meters and report width/height\n",
    "#\n",
    "# Assumption:\n",
    "#   - The measured object lies on the same plane as the chessboard. If the object is elevated,\n",
    "#     the homography mapping does not represent true 3D geometry and distances will be wrong.\n",
    "\n",
    "# ----------------------------\n",
    "# Runtime state\n",
    "# ----------------------------\n",
    "zoom_on = False\n",
    "zoom_center = None\n",
    "zoom_win = \"zoom\"\n",
    "\n",
    "# Clicked points in FULL-RES undistorted image coordinates (float x,y)\n",
    "pts = []\n",
    "drag_i = None\n",
    "cycle_i = 0\n",
    "last_dims_m = None\n",
    "\n",
    "newK = None\n",
    "last_size = None\n",
    "\n",
    "_last_zoom_origin = None\n",
    "_frame_i = 0\n",
    "\n",
    "# Board / homography state (FULL-RES undistorted image coords)\n",
    "_have_H = False\n",
    "_Hinv = None\n",
    "\n",
    "# Corner state (N = PATTERN_SIZE[0] * PATTERN_SIZE[1])\n",
    "_corners_full = None         # latest accepted corners (N,1,2) float32\n",
    "_corners_smooth = None       # EMA-smoothed corners (N,1,2) float32\n",
    "_prev_gray = None            # previous undistorted grayscale for LK tracking\n",
    "\n",
    "# ----------------------------\n",
    "# Load intrinsics\n",
    "# ----------------------------\n",
    "z = np.load(INTRINSICS_PATH, allow_pickle=True)\n",
    "K = z[\"camera_matrix\"]\n",
    "dist = z[\"dist_coeffs\"]\n",
    "\n",
    "# ----------------------------\n",
    "# Open camera (AUTO: phone stream else local webcam)\n",
    "# ----------------------------\n",
    "def _open_device():\n",
    "    cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_W)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_H)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        return None, None\n",
    "    ok, frame = cap.read()\n",
    "    if not ok or frame is None or frame.size == 0:\n",
    "        cap.release()\n",
    "        return None, None\n",
    "    return cap, frame\n",
    "\n",
    "def open_cam_auto():\n",
    "    # Prefer phone stream; fall back to local device if phone stream fails.\n",
    "    try:\n",
    "        cap, url, frame = open_phone_cap()\n",
    "        return cap, f\"phone:{url}\", frame\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    cap2, frame2 = _open_device()\n",
    "    if cap2 is not None:\n",
    "        return cap2, f\"device:{CAM_INDEX}\", frame2\n",
    "\n",
    "    raise RuntimeError(\"Couldn't open phone stream OR local webcam.\")\n",
    "\n",
    "cap, src, first = open_cam_auto()\n",
    "print(\"ESC=quit | C=clear | P=print | RClick toggle zoom | source:\", src)\n",
    "\n",
    "# ----------------------------\n",
    "# Geometry / drawing helpers\n",
    "# ----------------------------\n",
    "def compute_display_scale(h, w):\n",
    "    # Display scaling only; all computations remain in full-res coordinates.\n",
    "    return min(DISPLAY_MAX_W / w, DISPLAY_MAX_H / h, 1.0)\n",
    "\n",
    "def to_full_res(x, y, scale):\n",
    "    # Mouse coords (display) -> full-res coords (undistorted frame space)\n",
    "    return int(x / scale), int(y / scale)\n",
    "\n",
    "def to_disp(x_full, y_full, scale):\n",
    "    # Full-res coords -> display coords\n",
    "    return int(x_full * scale), int(y_full * scale)\n",
    "\n",
    "def nearest_point_index_full(x, y, pts_list, r=POINT_HIT_R_FULL):\n",
    "    # Nearest clicked point within hit radius (full-res coordinates)\n",
    "    if not pts_list:\n",
    "        return None\n",
    "    p = np.asarray(pts_list, dtype=np.float32)\n",
    "    d2 = (p[:, 0] - x) ** 2 + (p[:, 1] - y) ** 2\n",
    "    i = int(np.argmin(d2))\n",
    "    return i if d2[i] <= r * r else None\n",
    "\n",
    "def order_quad(pts4):\n",
    "    # Stable ordering: sort by angle around centroid, then rotate so top-left-ish is first\n",
    "    pts4 = np.asarray(pts4, dtype=np.float32)\n",
    "    c = pts4.mean(axis=0)\n",
    "    ang = np.arctan2(pts4[:, 1] - c[1], pts4[:, 0] - c[0])\n",
    "    pts4 = pts4[np.argsort(ang)]\n",
    "    s = pts4.sum(axis=1)\n",
    "    i0 = int(np.argmin(s))\n",
    "    return np.roll(pts4, -i0, axis=0)\n",
    "\n",
    "def quad_wh_m(world_xy4):\n",
    "    # Width/height as avg of opposite edges in board-plane metric coords\n",
    "    p = np.asarray(world_xy4, dtype=np.float64)\n",
    "    d01 = np.linalg.norm(p[1] - p[0])\n",
    "    d12 = np.linalg.norm(p[2] - p[1])\n",
    "    d23 = np.linalg.norm(p[3] - p[2])\n",
    "    d30 = np.linalg.norm(p[0] - p[3])\n",
    "    w = 0.5 * (d01 + d23)\n",
    "    h = 0.5 * (d12 + d30)\n",
    "    return w, h\n",
    "\n",
    "def zoom_crop_bounds(img_shape, center_xy, radius):\n",
    "    h, w = img_shape[:2]\n",
    "    cx, cy = center_xy\n",
    "    x1 = max(0, cx - radius); x2 = min(w, cx + radius)\n",
    "    y1 = max(0, cy - radius); y2 = min(h, cy + radius)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def make_zoom_view(img_bgr, center_xy, radius, factor):\n",
    "    # Crop around zoom center (full-res), then scale up for a separate zoom window.\n",
    "    x1, y1, x2, y2 = zoom_crop_bounds(img_bgr.shape, center_xy, radius)\n",
    "    crop = img_bgr[y1:y2, x1:x2].copy()\n",
    "    if crop.size == 0:\n",
    "        return None, None\n",
    "    zoom = cv2.resize(crop, None, fx=factor, fy=factor, interpolation=cv2.INTER_NEAREST)\n",
    "    zh, zw = zoom.shape[:2]\n",
    "    cv2.line(zoom, (zw // 2, 0), (zw // 2, zh), (0, 255, 0), 1)\n",
    "    cv2.line(zoom, (0, zh // 2), (zw, zh // 2), (0, 255, 0), 1)\n",
    "    return zoom, (x1, y1)\n",
    "\n",
    "def draw_marker(img, x, y, color=(0, 255, 0), ring_r=POINT_RING_R, ring_th=POINT_RING_TH, center_r=POINT_CENTER_R):\n",
    "    # Hollow ring + center dot marker; size is in screen pixels (constant in main + zoom)\n",
    "    x = int(round(x)); y = int(round(y))\n",
    "    cv2.circle(img, (x, y), ring_r, color, ring_th, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, (x, y), center_r, color, -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "def draw_text(img, lines, x=18, y=40, dy=34):\n",
    "    # White text with black outline for readability\n",
    "    for i, s in enumerate(lines):\n",
    "        yy = y + i * dy\n",
    "        cv2.putText(img, s, (x, yy), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 0), 5)\n",
    "        cv2.putText(img, s, (x, yy), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (255, 255, 255), 2)\n",
    "\n",
    "# ----------------------------\n",
    "# Mouse callbacks\n",
    "# ----------------------------\n",
    "main_win = \"Measure: LClick add/drag | RClick zoom toggle | C clear | P print | ESC quit\"\n",
    "\n",
    "def mouse_zoom(event, x, y, flags, param):\n",
    "    # Zoom window mouse coordinates map back to full-res using:\n",
    "    #   full_x = origin_x + x / zoom_factor\n",
    "    #   full_y = origin_y + y / zoom_factor\n",
    "    global pts, drag_i, cycle_i, zoom_on, zoom_center, _last_zoom_origin\n",
    "\n",
    "    if not zoom_on or zoom_center is None or _last_zoom_origin is None:\n",
    "        return\n",
    "\n",
    "    ox, oy = _last_zoom_origin\n",
    "    fx = float(ox + (x / zoom_factor))\n",
    "    fy = float(oy + (y / zoom_factor))\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        zoom_on = False\n",
    "        zoom_center = None\n",
    "        try:\n",
    "            cv2.destroyWindow(zoom_win)\n",
    "        except:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        i = nearest_point_index_full(fx, fy, pts, r=POINT_HIT_R_FULL)\n",
    "        if i is not None:\n",
    "            drag_i = i\n",
    "            pts[drag_i] = (fx, fy)\n",
    "            return\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            drag_i = cycle_i\n",
    "            cycle_i = (cycle_i + 1) % 4\n",
    "            pts[drag_i] = (fx, fy)\n",
    "            return\n",
    "\n",
    "        if len(pts) < 4:\n",
    "            pts.append((fx, fy))\n",
    "            return\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drag_i is not None:\n",
    "            pts[drag_i] = (fx, fy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drag_i = None\n",
    "\n",
    "def mouse_main(event, x, y, flags, param):\n",
    "    # Main window mouse: add/drag points; right click toggles zoom\n",
    "    global pts, drag_i, cycle_i, zoom_on, zoom_center, disp_scale\n",
    "\n",
    "    fx, fy = to_full_res(x, y, disp_scale)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        if not zoom_on:\n",
    "            zoom_center = (fx, fy)\n",
    "            zoom_on = True\n",
    "            cv2.namedWindow(zoom_win)\n",
    "            cv2.setMouseCallback(zoom_win, mouse_zoom)\n",
    "        else:\n",
    "            zoom_on = False\n",
    "            zoom_center = None\n",
    "            try:\n",
    "                cv2.destroyWindow(zoom_win)\n",
    "            except:\n",
    "                pass\n",
    "        return\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        i = nearest_point_index_full(fx, fy, pts, r=POINT_HIT_R_FULL)\n",
    "\n",
    "        if i is not None:\n",
    "            drag_i = i\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "            return\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            drag_i = cycle_i\n",
    "            cycle_i = (cycle_i + 1) % 4\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "            return\n",
    "\n",
    "        if len(pts) < 4:\n",
    "            pts.append((float(fx), float(fy)))\n",
    "            return\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drag_i is not None:\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drag_i = None\n",
    "\n",
    "cv2.namedWindow(main_win)\n",
    "cv2.setMouseCallback(main_win, mouse_main)\n",
    "\n",
    "# ----------------------------\n",
    "# Chessboard detection setup\n",
    "# ----------------------------\n",
    "# Board-plane coordinates of each inner corner in meters (index-aligned with OpenCV corner ordering).\n",
    "nx, ny = PATTERN_SIZE\n",
    "world_xy = (np.mgrid[0:nx, 0:ny].T.reshape(-1, 2).astype(np.float32) * float(SQUARE_M))\n",
    "\n",
    "SB_FLAGS = (cv2.CALIB_CB_EXHAUSTIVE | cv2.CALIB_CB_ACCURACY)\n",
    "CLASSIC_FLAGS = (cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)) if CLAHE_ON else None\n",
    "\n",
    "def detect_board_fast(gray_full):\n",
    "    # Downsample for detection speed (full-res/4K detection was too slow); scale corners back to full-res coords.\n",
    "    if DETECT_SCALE != 1.0:\n",
    "        g = cv2.resize(gray_full, (0, 0), fx=DETECT_SCALE, fy=DETECT_SCALE, interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        g = gray_full\n",
    "\n",
    "    # Optional local-contrast boost to improve detection under uneven lighting.\n",
    "    g1 = clahe.apply(g) if clahe is not None else g\n",
    "\n",
    "    # Prefer SB detector (more robust); try normal then inverted.\n",
    "    if SB_FIRST:\n",
    "        ok, corners = cv2.findChessboardCornersSB(g1, PATTERN_SIZE, SB_FLAGS)\n",
    "        if ok:\n",
    "            corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "            return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "        ok, corners = cv2.findChessboardCornersSB(255 - g1, PATTERN_SIZE, SB_FLAGS)\n",
    "        if ok:\n",
    "            corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "            return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Fallback: classic detector + subpixel refinement.\n",
    "    ok, corners = cv2.findChessboardCorners(g1, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "    if ok:\n",
    "        corners = cv2.cornerSubPix(g1, corners, (11, 11), (-1, -1), term)\n",
    "        corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "        return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    ok, corners = cv2.findChessboardCorners(255 - g1, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "    if ok:\n",
    "        corners = cv2.cornerSubPix(255 - g1, corners, (11, 11), (-1, -1), term)\n",
    "        corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "        return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    return None\n",
    "\n",
    "# ----------------------------\n",
    "# Corner tracking (LK) + gating + smoothing + robust homography\n",
    "# ----------------------------\n",
    "# LK tracking provides smooth corner motion between detections.\n",
    "# Gating prevents bad tracks from corrupting pose.\n",
    "# EMA reduces visible jitter in the estimated corners.\n",
    "# RANSAC homography fit tolerates a small number of remaining bad points.\n",
    "\n",
    "N_CORNERS = int(PATTERN_SIZE[0] * PATTERN_SIZE[1])\n",
    "MIN_GOOD_COUNT = int(np.ceil(float(TRACK_MIN_FRAC) * N_CORNERS))\n",
    "\n",
    "LK_WIN = (21, 21)\n",
    "LK_MAX_LEVEL = 3\n",
    "LK_CRIT = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)\n",
    "\n",
    "FB_ERR_MAX_PX = 1.25   # forward-backward error threshold (pixels)\n",
    "MAX_JUMP_PX = 30.0     # max per-corner displacement per frame (pixels)\n",
    "\n",
    "def ema_corners(prev_smooth, new_corners, alpha):\n",
    "    # Exponential moving average in coordinate space to reduce frame-to-frame jitter.\n",
    "    if prev_smooth is None:\n",
    "        return new_corners.copy()\n",
    "    a = float(alpha)\n",
    "    return ((1.0 - a) * prev_smooth + a * new_corners).astype(np.float32)\n",
    "\n",
    "def track_corners_robust(prev_gray, gray, corners_prev):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      corners_next (N,1,2) float32  OR  None if tracking is considered failed\n",
    "      good_mask    (N,) bool\n",
    "\n",
    "    Gating logic:\n",
    "      - forward LK must succeed\n",
    "      - backward LK must succeed (forward-backward consistency check)\n",
    "      - forward-backward error <= FB_ERR_MAX_PX\n",
    "      - per-corner displacement <= MAX_JUMP_PX\n",
    "\n",
    "    If enough corners pass gating, failed corners are pinned to their previous positions\n",
    "    so corner ordering stays consistent and pose estimation is not poisoned.\n",
    "    \"\"\"\n",
    "    p0 = corners_prev.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Forward track: prev -> curr\n",
    "    p1, st1, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        prev_gray, gray, p0, None,\n",
    "        winSize=LK_WIN, maxLevel=LK_MAX_LEVEL, criteria=LK_CRIT,\n",
    "        flags=0, minEigThreshold=1e-4\n",
    "    )\n",
    "    if p1 is None or st1 is None:\n",
    "        return None, None\n",
    "\n",
    "    # Backward track: curr -> prev (forward-backward check)\n",
    "    p0b, st2, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        gray, prev_gray, p1, None,\n",
    "        winSize=LK_WIN, maxLevel=LK_MAX_LEVEL, criteria=LK_CRIT,\n",
    "        flags=0, minEigThreshold=1e-4\n",
    "    )\n",
    "    if p0b is None or st2 is None:\n",
    "        return None, None\n",
    "\n",
    "    st1 = st1.reshape(-1).astype(bool)\n",
    "    st2 = st2.reshape(-1).astype(bool)\n",
    "\n",
    "    p0_xy = p0.reshape(-1, 2)\n",
    "    p1_xy = p1.reshape(-1, 2)\n",
    "    p0b_xy = p0b.reshape(-1, 2)\n",
    "\n",
    "    fb_err = np.linalg.norm(p0_xy - p0b_xy, axis=1)       # forward-backward consistency\n",
    "    disp = np.linalg.norm(p1_xy - p0_xy, axis=1)          # per-frame motion magnitude\n",
    "\n",
    "    good = st1 & st2 & (fb_err <= float(FB_ERR_MAX_PX)) & (disp <= float(MAX_JUMP_PX))\n",
    "    good_n = int(good.sum())\n",
    "\n",
    "    # Not enough reliable points -> tracking failure (forces re-detect upstream if configured)\n",
    "    if good_n < MIN_GOOD_COUNT:\n",
    "        return None, good\n",
    "\n",
    "    # Preserve ordering: bad corners stay at previous location for this frame\n",
    "    p1_fix = p1.copy()\n",
    "    if (~good).any():\n",
    "        p1_fix.reshape(-1, 2)[~good] = p0_xy[~good]\n",
    "\n",
    "    return p1_fix.astype(np.float32), good\n",
    "\n",
    "def update_hinv_from_corners(corners_full):\n",
    "    \"\"\"\n",
    "    Computes H(world->image) with RANSAC, then stores Hinv(image->world).\n",
    "    RANSAC prevents a small number of outlier corners from collapsing H.\n",
    "    \"\"\"\n",
    "    global _have_H, _Hinv\n",
    "\n",
    "    if corners_full is None:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    img_pts = corners_full.reshape(-1, 2).astype(np.float32)\n",
    "\n",
    "    H_world_to_img, inliers = cv2.findHomography(\n",
    "        world_xy, img_pts, method=cv2.RANSAC, ransacReprojThreshold=2.0\n",
    "    )\n",
    "    if H_world_to_img is None or inliers is None:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    # Require enough inliers to trust the pose\n",
    "    if int(inliers.sum()) < MIN_GOOD_COUNT:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        _Hinv = np.linalg.inv(H_world_to_img)\n",
    "    except np.linalg.LinAlgError:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    _have_H = True\n",
    "\n",
    "# ----------------------------\n",
    "# Main loop\n",
    "# ----------------------------\n",
    "print(\"ESC=quit | C=clear | P=print | RClick toggle zoom\")\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok or frame is None:\n",
    "        break\n",
    "\n",
    "    # (1) Undistort\n",
    "    h, w = frame.shape[:2]\n",
    "    if newK is None or last_size != (w, h):\n",
    "        # Cache newK per resolution; alpha=1 keeps full FOV (may include black borders).\n",
    "        newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), 1)\n",
    "        last_size = (w, h)\n",
    "\n",
    "    und = cv2.undistort(frame, K, dist, None, newK)\n",
    "    gray = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # (2) Update board pose:\n",
    "    #     - periodic re-detection anchors pose and prevents drift\n",
    "    #     - LK tracking fills in between detections for stability/speed\n",
    "    need_detect = (_corners_full is None) or ((_frame_i % DETECT_EVERY_N) == 0)\n",
    "\n",
    "    if not need_detect and _prev_gray is not None and _corners_full is not None:\n",
    "        tracked_corners, good_mask = track_corners_robust(_prev_gray, gray, _corners_full)\n",
    "\n",
    "        if tracked_corners is None:\n",
    "            # Tracking failure: either force a re-detect or mark pose invalid (depending on toggle).\n",
    "            if REDETECT_ON_TRACK_FAIL:\n",
    "                need_detect = True\n",
    "            else:\n",
    "                _have_H = False\n",
    "                _Hinv = None\n",
    "        else:\n",
    "            # Tracking success: smooth -> update homography from smoothed corners.\n",
    "            _corners_full = tracked_corners\n",
    "            _corners_smooth = ema_corners(_corners_smooth, _corners_full, CORNER_EMA_ALPHA)\n",
    "            update_hinv_from_corners(_corners_smooth)\n",
    "\n",
    "    if need_detect:\n",
    "        detected = detect_board_fast(gray)\n",
    "        if detected is not None:\n",
    "            _corners_full = detected\n",
    "            _corners_smooth = ema_corners(_corners_smooth, _corners_full, CORNER_EMA_ALPHA)\n",
    "            update_hinv_from_corners(_corners_smooth)\n",
    "        else:\n",
    "            _have_H = False\n",
    "            _Hinv = None\n",
    "\n",
    "    # Store current gray for next frame’s tracking\n",
    "    _prev_gray = gray\n",
    "\n",
    "    # (3) Display image (scaled), but keep all point math in full-res coords\n",
    "    disp_scale = compute_display_scale(und.shape[0], und.shape[1])\n",
    "    disp = und if disp_scale >= 1.0 else cv2.resize(\n",
    "        und,\n",
    "        (int(und.shape[1] * disp_scale), int(und.shape[0] * disp_scale)),\n",
    "        interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "\n",
    "    # Draw detected corners (use smoothed corners to avoid visible jitter)\n",
    "    corners_for_draw = _corners_smooth if _corners_smooth is not None else _corners_full\n",
    "    if corners_for_draw is not None:\n",
    "        corners_disp = corners_for_draw.copy()\n",
    "        corners_disp[:, 0, 0] *= disp_scale\n",
    "        corners_disp[:, 0, 1] *= disp_scale\n",
    "        cv2.drawChessboardCorners(disp, PATTERN_SIZE, corners_disp, True)\n",
    "\n",
    "    # (4) Draw clicked points + quad; compute metric dims if homography is valid\n",
    "    if len(pts) > 0:\n",
    "        for i, (x, y) in enumerate(pts):\n",
    "            dx, dy = to_disp(x, y, disp_scale)\n",
    "            draw_marker(disp, dx, dy)\n",
    "            cv2.putText(\n",
    "                disp, str(i + 1),\n",
    "                (dx + POINT_RING_R + 4, dy - POINT_RING_R - 2),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, LABEL_SCALE, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            quad = order_quad(pts)\n",
    "            quad_disp = (quad * disp_scale).astype(np.float32)\n",
    "            cv2.polylines(\n",
    "                disp, [quad_disp.astype(np.int32).reshape(-1, 1, 2)],\n",
    "                True, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            if _have_H and _Hinv is not None:\n",
    "                pts_img = quad.astype(np.float32).reshape(-1, 1, 2)\n",
    "                # Hinv maps image->world (board plane meters)\n",
    "                pts_world = cv2.perspectiveTransform(pts_img, _Hinv).reshape(-1, 2)\n",
    "                w_m, h_m = quad_wh_m(pts_world)\n",
    "                last_dims_m = (float(w_m), float(h_m))\n",
    "\n",
    "    # (5) Status overlay\n",
    "    status = [\n",
    "        f\"board: {'OK' if _have_H else 'NOT FOUND'} | points: {len(pts)}/4 | zoom: {'ON' if zoom_on else 'OFF'}\"\n",
    "    ]\n",
    "    if last_dims_m is not None:\n",
    "        status.append(f\"W: {last_dims_m[0] * 1000.0:.1f} mm   H: {last_dims_m[1] * 1000.0:.1f} mm\")\n",
    "    else:\n",
    "        status.append(\"W: --   H: --\")\n",
    "\n",
    "    draw_text(disp, status)\n",
    "    cv2.imshow(main_win, disp)\n",
    "\n",
    "    # (6) Zoom window\n",
    "    if zoom_on:\n",
    "        if zoom_center is None:\n",
    "            zoom_center = (w // 2, h // 2)\n",
    "\n",
    "        zoom_img, origin = make_zoom_view(und, zoom_center, zoom_radius, zoom_factor)\n",
    "        _last_zoom_origin = origin\n",
    "\n",
    "        if zoom_img is not None and origin is not None:\n",
    "            ox, oy = origin\n",
    "\n",
    "            for i, (px, py) in enumerate(pts):\n",
    "                zx = int((px - ox) * zoom_factor)\n",
    "                zy = int((py - oy) * zoom_factor)\n",
    "                if 0 <= zx < zoom_img.shape[1] and 0 <= zy < zoom_img.shape[0]:\n",
    "                    draw_marker(zoom_img, zx, zy)\n",
    "                    cv2.putText(\n",
    "                        zoom_img, str(i + 1),\n",
    "                        (zx + POINT_RING_R + 4, zy - POINT_RING_R - 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, LABEL_SCALE, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "            cv2.imshow(zoom_win, zoom_img)\n",
    "\n",
    "    # (7) Key handling\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key in (ord('c'), ord('C')):\n",
    "        pts = []\n",
    "        drag_i = None\n",
    "        cycle_i = 0\n",
    "        last_dims_m = None\n",
    "    if key in (ord('p'), ord('P')):\n",
    "        if last_dims_m is None:\n",
    "            print(\"No measurement yet (need 4 points + board found).\")\n",
    "        else:\n",
    "            print(f\"W: {last_dims_m[0] * 1000.0:.1f} mm | H: {last_dims_m[1] * 1000.0:.1f} mm\")\n",
    "\n",
    "    _frame_i += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if last_dims_m is None:\n",
    "    raise RuntimeError(\"No measurement captured (need 4 clicked points + board found).\")\n",
    "\n",
    "print(\"Measured dimensions:\")\n",
    "print(f\"  Width : {last_dims_m[0] * 1000.0:.1f} mm\")\n",
    "print(f\"  Height: {last_dims_m[1] * 1000.0:.1f} mm\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

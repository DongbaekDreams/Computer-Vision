{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a22ac72",
   "metadata": {},
   "source": [
    "# README (COMMON) — Camera calibration + live measurement (Chessboard, phone stream or webcam)\n",
    "\n",
    "## What this notebook does\n",
    "This notebook is split into 4 code “blocks” (cells) that together let you:\n",
    "1) Open a phone MJPEG stream (or webcam fallback)\n",
    "2) Optionally capture calibration frames\n",
    "3) Calibrate (or load) camera intrinsics (K, dist)\n",
    "4) Optionally sanity-check undistortion (side-by-side mosaic)\n",
    "5) Run a live measurement tool that maps 4 clicked image points onto the chessboard plane (meters) and reports width/height (mm)\n",
    "\n",
    "## Requirements\n",
    "- Python 3.x\n",
    "- Packages:\n",
    "  - `opencv-python`\n",
    "  - `numpy`\n",
    "\n",
    "## Files / outputs\n",
    "- `calib_frames_phone/` (folder): saved calibration images if you capture frames\n",
    "- `camera_intrinsics_phone.npz` (file): saved intrinsics (K, dist, image_size, metadata)\n",
    "\n",
    "## Chessboard assumptions\n",
    "- Board is 8×8 squares → **7×7 inner corners**: `PATTERN_SIZE = (7, 7)`\n",
    "- Square size is derived from `BOARD_OUTER_MM / 8` → `SQUARE_MM`\n",
    "- Units:\n",
    "  - Calibration object points are in **meters**\n",
    "  - Live measurement prints **mm**\n",
    "\n",
    "## How to run (typical workflows)\n",
    "\n",
    "### Workflow A (already calibrated)\n",
    "1) **Block 1**: leave defaults; ensure `INTRINSICS_PATH` exists.\n",
    "2) **Block 2**: keep `PRE_CALIBRATED=True` (loads intrinsics)\n",
    "3) (Optional) **Block 3**: set `SHOW_COMPARISON=True` to sanity-check undistortion\n",
    "4) **Block 4**: run live measurement and click 4 points to measure\n",
    "\n",
    "### Workflow B (calibrate from scratch)\n",
    "1) **Block 1**: set `PRE_CALIBRATED=False` and verify:\n",
    "   - `CAM_BASE` points to your phone-stream control page\n",
    "   - `PATTERN_SIZE`, `BOARD_OUTER_MM` match your printed board\n",
    "2) **Block 2**(A): capture ~15–30 frames with varied angles/distances (SPACE to save)\n",
    "3) **Block 2**(B): calibrate; saves `camera_intrinsics_phone.npz`\n",
    "4) (Optional) **Block 3**: sanity-check undistortion\n",
    "5) **Block 4**: run live measurement\n",
    "\n",
    "## Controls (reused across relevant blocks)\n",
    "- ESC: quit\n",
    "- Block 2 capture: SPACE save frame\n",
    "- Block 4 measurement:\n",
    "  - Left-click: add / drag points\n",
    "  - Right-click: toggle zoom window\n",
    "  - C: clear points\n",
    "  - P: print last measurement to console\n",
    "\n",
    "## Troubleshooting quick hits\n",
    "- **Phone page opens in browser, but OpenCV can’t read stream**:\n",
    "  - Open `CAM_BASE` in browser → right-click video → copy “video address”\n",
    "  - Set `CAM_BASE` to that direct stream URL or extend `COMMON_STREAM_PATHS`\n",
    "- **No chessboard detections**:\n",
    "  - Improve lighting, reduce glare, fill more of frame, add angles\n",
    "  - Enable `CLAHE_ON=True` (already in your config)\n",
    "- **Live measurement says board NOT FOUND**:\n",
    "  - Move board to be more fronto-parallel, improve contrast\n",
    "  - Wait for periodic re-detection (`DETECT_EVERY_N`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b0938",
   "metadata": {},
   "source": [
    "# Block 1 — Shared config + helpers (used by all cells)\n",
    "\n",
    "## Purpose\n",
    "Defines all shared configuration and helper functions used by later blocks:\n",
    "- Chessboard geometry (square size, inner-corner pattern)\n",
    "- Phone stream discovery helpers that scrape `CAM_BASE` and try common MJPEG endpoints\n",
    "- Object-point generator for calibration (`mk_object_points`)\n",
    "\n",
    "## Key settings to change\n",
    "- `PRE_CALIBRATED`:\n",
    "  - `True`: skip capture + calibration; load `camera_intrinsics_phone.npz`\n",
    "  - `False`: capture and calibrate from images in `calib_frames_phone/`\n",
    "- `SHOW_COMPARISON`:\n",
    "  - `True`: enable Block 3 undistortion mosaic\n",
    "- `CAM_BASE`: base page for your phone stream (IP Webcam / DroidCam-like servers)\n",
    "- `BOARD_OUTER_MM`, `PATTERN_SIZE`:\n",
    "  - Must match your printed chessboard\n",
    "  - 8×8 squares → `PATTERN_SIZE=(7,7)`\n",
    "- Output paths:\n",
    "  - `CALIB_DIR` folder for captured frames\n",
    "  - `INTRINSICS_PATH` for saved intrinsics `.npz`\n",
    "\n",
    "## What it provides to downstream blocks\n",
    "- `open_phone_cap()` → returns `(cap, chosen_url, first_frame)`\n",
    "- `mk_object_points(pattern_size, square_m)` → 3D chessboard corner points in meters\n",
    "\n",
    "## Notes / assumptions\n",
    "- Stream endpoint discovery is best-effort:\n",
    "  - It scrapes HTML for `href/src` URLs containing common MJPEG keywords\n",
    "  - It tries `COMMON_STREAM_PATHS` fallbacks\n",
    "- If none work, it raises an error telling you how to copy the direct stream URL from the browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# TOP CELL — Shared config + helpers (used by all cells below)\n",
    "# ============================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Notebook toggles\n",
    "# ----------------------------\n",
    "PRE_CALIBRATED = False\n",
    "SHOW_COMPARISON = True\n",
    "\n",
    "# ----------------------------\n",
    "# Board config\n",
    "# ----------------------------\n",
    "BOARD_OUTER_MM = 336.0\n",
    "SQUARE_MM = BOARD_OUTER_MM / 8.0\n",
    "SQUARE_M = SQUARE_MM / 1000.0\n",
    "PATTERN_SIZE = (7, 7)  # 8x8 squares => 7x7 inner corners\n",
    "\n",
    "# ----------------------------\n",
    "# Phone stream base page\n",
    "# ----------------------------\n",
    "CAM_BASE = \"http://192.168.1.70:8080/\"  # base control page that works in your browser\n",
    "\n",
    "# ----------------------------\n",
    "# Files\n",
    "# ----------------------------\n",
    "CALIB_DIR = Path(\"calib_frames_phone\")\n",
    "INTRINSICS_PATH = \"camera_intrinsics_phone.npz\"\n",
    "\n",
    "# ----------------------------\n",
    "# Capture preview sizing\n",
    "# ----------------------------\n",
    "PREVIEW_MAX_W = 1600\n",
    "PREVIEW_MAX_H = 900\n",
    "\n",
    "# ----------------------------\n",
    "# Stream endpoint discovery\n",
    "# ----------------------------\n",
    "COMMON_STREAM_PATHS = [\n",
    "    \"video\",\n",
    "    \"videofeed\",\n",
    "    \"mjpeg\", \"mjpegfeed\",\n",
    "    \"live\", \"stream\",\n",
    "    \"?action=stream\",\n",
    "    \"video?x.mjpeg\",\n",
    "    \"mjpg/video.mjpg\",\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Live measurement config (CELL 3 reads these)\n",
    "# ----------------------------\n",
    "CAM_INDEX = 0\n",
    "CAPTURE_W = 3840\n",
    "CAPTURE_H = 2160\n",
    "\n",
    "# Detection cadence / preprocess\n",
    "DETECT_EVERY_N = 12\n",
    "DETECT_SCALE = 0.45\n",
    "CLAHE_ON = True\n",
    "SB_FIRST = True\n",
    "\n",
    "# Tracking / smoothing\n",
    "TRACK_MIN_FRAC = 0.75\n",
    "CORNER_EMA_ALPHA = 0.20\n",
    "REDETECT_ON_TRACK_FAIL = True\n",
    "\n",
    "# LK safety rails (prevents collapse / shoot-off)\n",
    "FB_ERR_MAX_PX = 1.25\n",
    "MAX_JUMP_PX = 30.0\n",
    "\n",
    "# Display sizing\n",
    "DISPLAY_MAX_W = 1600\n",
    "DISPLAY_MAX_H = 900\n",
    "\n",
    "# Point rendering\n",
    "POINT_RING_R = 8\n",
    "POINT_RING_TH = 2\n",
    "POINT_CENTER_R = 1\n",
    "POINT_HIT_R_FULL = 12\n",
    "LABEL_SCALE = 0.6\n",
    "\n",
    "# Zoom\n",
    "zoom_factor = 4\n",
    "zoom_radius = 180\n",
    "zoom_win = \"zoom\"\n",
    "\n",
    "# ----------------------------\n",
    "# URL discovery helpers\n",
    "# ----------------------------\n",
    "def _fetch_html(url, timeout=3.0):\n",
    "    req = urllib.request.Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    with urllib.request.urlopen(req, timeout=timeout) as r:\n",
    "        return r.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def _extract_stream_urls_from_html(base_url, html):\n",
    "    candidates = set()\n",
    "    for m in re.finditer(r'(?:href|src)\\s*=\\s*[\"\\']([^\"\\']+)[\"\\']', html, flags=re.IGNORECASE):\n",
    "        u = m.group(1).strip()\n",
    "        if not u:\n",
    "            continue\n",
    "        low = u.lower()\n",
    "        if any(k in low for k in [\"mjpeg\", \"mjpg\", \"videofeed\", \"video\", \"stream\", \"action=stream\"]):\n",
    "            candidates.add(urllib.parse.urljoin(base_url, u))\n",
    "    return list(candidates)\n",
    "\n",
    "def _try_open_url(url):\n",
    "    backends = [None, cv2.CAP_MSMF]\n",
    "    try:\n",
    "        backends.append(cv2.CAP_FFMPEG)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    for be in backends:\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(url) if be is None else cv2.VideoCapture(url, be)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if cap is None or not cap.isOpened():\n",
    "            try:\n",
    "                cap.release()\n",
    "            except:\n",
    "                pass\n",
    "            continue\n",
    "        ok, frame = cap.read()\n",
    "        if ok and frame is not None and frame.size > 0:\n",
    "            return cap, frame\n",
    "        cap.release()\n",
    "    return None, None\n",
    "\n",
    "def open_phone_cap():\n",
    "    base = CAM_BASE if CAM_BASE.endswith(\"/\") else (CAM_BASE + \"/\")\n",
    "    html = _fetch_html(base, timeout=3.0)\n",
    "    scraped = _extract_stream_urls_from_html(base, html)\n",
    "    fallbacks = [urllib.parse.urljoin(base, p) for p in COMMON_STREAM_PATHS]\n",
    "\n",
    "    seen = set()\n",
    "    candidates = []\n",
    "    for u in scraped + fallbacks:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            candidates.append(u)\n",
    "\n",
    "    for u in candidates:\n",
    "        cap, frame = _try_open_url(u)\n",
    "        if cap is not None:\n",
    "            return cap, u, frame\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"Browser opens CAM_BASE, but OpenCV can't find a readable stream endpoint.\\n\"\n",
    "        \"Fix:\\n\"\n",
    "        \"  - Open CAM_BASE in your browser\\n\"\n",
    "        \"  - Right-click the video -> Copy video address\\n\"\n",
    "        \"  - Set CAM_BASE to that direct stream URL (or paste it here)\\n\"\n",
    "    )\n",
    "\n",
    "def mk_object_points(pattern_size, square_m):\n",
    "    nx, ny = pattern_size\n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2) * square_m\n",
    "    return objp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957896c",
   "metadata": {},
   "source": [
    "# Block 2 — Capture frames + Calibrate (or load) intrinsics\n",
    "\n",
    "## Purpose\n",
    "Two-part block:\n",
    "(A) Capture calibration frames from the phone stream into `CALIB_DIR` (only if `PRE_CALIBRATED=False`)\n",
    "(B) Either load intrinsics from `INTRINSICS_PATH` (if `PRE_CALIBRATED=True`) or calibrate from saved frames and save intrinsics\n",
    "\n",
    "## How to execute\n",
    "- If you already have `camera_intrinsics_phone.npz`:\n",
    "  - Set `PRE_CALIBRATED=True`\n",
    "  - Run Block 2 → it loads `K`, `dist`, `image_size`\n",
    "- If you need to calibrate:\n",
    "  - Set `PRE_CALIBRATED=False`\n",
    "  - Run Block 2:\n",
    "    - Part (A): press SPACE to save multiple frames (15–30 recommended), ESC to quit capture\n",
    "    - Part (B): runs chessboard detection on saved `.jpg` frames and calibrates\n",
    "\n",
    "## Output\n",
    "- When calibrating: writes `camera_intrinsics_phone.npz` with:\n",
    "  - `camera_matrix` (K), `dist_coeffs` (dist), `image_size`\n",
    "  - metadata: `pattern_size`, `square_length_m`, `board_outer_mm`, `cam_base`, `rms`\n",
    "\n",
    "## Detection details (what it tries)\n",
    "- Preprocess: CLAHE (contrast boost)\n",
    "- Primary detector: `cv2.findChessboardCornersSB` on normal and inverted images\n",
    "- Fallback: classic `findChessboardCorners` + `cornerSubPix`\n",
    "\n",
    "## Common failure modes\n",
    "- “No images found”: you didn’t capture frames or `CALIB_DIR` path is wrong\n",
    "- “No usable chessboard detections”:\n",
    "  - improve lighting, reduce glare, include more tilt/rotation, fill frame more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9160bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping capture (PRE_CALIBRATED=True)\n",
      "Loaded intrinsics from camera_intrinsics_phone.npz\n",
      "image_size: (np.int64(1920), np.int64(1080))\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# (A) Capture frames (optional)\n",
    "# ----------------------------\n",
    "# Captures full-res frames from the phone stream into CALIB_DIR.\n",
    "# Preview is mirrored and downscaled only for usability; saved images are original frames.\n",
    "if not PRE_CALIBRATED:\n",
    "    CALIB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cap, chosen_url, first = open_phone_cap()\n",
    "    h0, w0 = first.shape[:2]\n",
    "    print(\"Opened stream:\", chosen_url)\n",
    "    print(f\"Stream resolution: {w0}x{h0}\")\n",
    "    print(\"SPACE=save | ESC=quit\")\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            print(\"Frame read failed; exiting.\")\n",
    "            break\n",
    "\n",
    "        preview = cv2.flip(frame, 1)\n",
    "\n",
    "        ph, pw = preview.shape[:2]\n",
    "        scale = min(PREVIEW_MAX_W / pw, PREVIEW_MAX_H / ph, 1.0)\n",
    "        if scale < 1.0:\n",
    "            preview = cv2.resize(\n",
    "                preview,\n",
    "                (int(pw * scale), int(ph * scale)),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"PHONE: SPACE=save | ESC=quit\", preview)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 27:  # ESC\n",
    "            print(\"ESC pressed; exiting.\")\n",
    "            break\n",
    "\n",
    "        if key == 32:  # SPACE\n",
    "            fname = CALIB_DIR / f\"frame_{idx:04d}.jpg\"\n",
    "            ok_write = cv2.imwrite(str(fname), frame, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "            print(f\"Saved {fname}\" if ok_write else f\"Failed to save {fname}\")\n",
    "            idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Skipping capture (PRE_CALIBRATED=True)\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# (B) Calibrate or load intrinsics\n",
    "# ----------------------------\n",
    "# If PRE_CALIBRATED:\n",
    "#   - Load K, dist, image_size from INTRINSICS_PATH\n",
    "# Else:\n",
    "#   - Detect chessboard corners on saved images\n",
    "#   - Run cv2.calibrateCamera\n",
    "#   - Save to INTRINSICS_PATH\n",
    "if PRE_CALIBRATED:\n",
    "    z = np.load(INTRINSICS_PATH, allow_pickle=True)\n",
    "    K = z[\"camera_matrix\"]\n",
    "    dist = z[\"dist_coeffs\"]\n",
    "    image_size = tuple(z[\"image_size\"])\n",
    "    print(\"Loaded intrinsics from\", INTRINSICS_PATH)\n",
    "    print(\"image_size:\", image_size)\n",
    "else:\n",
    "    objp = mk_object_points(PATTERN_SIZE, SQUARE_M)\n",
    "\n",
    "    objpoints = []  # per-image 3D corner locations in board coordinates\n",
    "    imgpoints = []  # per-image 2D detected corner locations in image coordinates\n",
    "    image_size = None\n",
    "\n",
    "    SB_FLAGS = (cv2.CALIB_CB_EXHAUSTIVE | cv2.CALIB_CB_ACCURACY)\n",
    "    CLASSIC_FLAGS = (cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
    "\n",
    "    # CLAHE boosts local contrast, often improves chessboard detection on phone streams.\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "\n",
    "    img_files = sorted(glob.glob(str(CALIB_DIR / \"*.jpg\")))\n",
    "    if not img_files:\n",
    "        raise RuntimeError(f\"No images found in {CALIB_DIR}. Capture frames first (PRE_CALIBRATED=False).\")\n",
    "\n",
    "    for fname in img_files:\n",
    "        img = cv2.imread(fname)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calibration assumes consistent image size for all samples.\n",
    "        if image_size is None:\n",
    "            image_size = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "        # Preprocess for detection.\n",
    "        g = clahe.apply(gray)\n",
    "\n",
    "        # Preferred: findChessboardCornersSB (robust) on normal and inverted.\n",
    "        ok, corners = cv2.findChessboardCornersSB(g, PATTERN_SIZE, SB_FLAGS)\n",
    "        if not ok:\n",
    "            ok, corners = cv2.findChessboardCornersSB(255 - g, PATTERN_SIZE, SB_FLAGS)\n",
    "\n",
    "        # Fallback: classic detector + subpixel refinement (normal only, as in your code).\n",
    "        if not ok:\n",
    "            ok, corners = cv2.findChessboardCorners(g, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "            if ok:\n",
    "                corners = cv2.cornerSubPix(g, corners, (11, 11), (-1, -1), term)\n",
    "\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        objpoints.append(objp.copy())\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "    n = len(imgpoints)\n",
    "    print(\"chessboard detections:\", n, \"image_size:\", image_size)\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No usable chessboard detections. Improve lighting/contrast, reduce glare, \"\n",
    "            \"fill frame more, add varied angles.\"\n",
    "        )\n",
    "\n",
    "    rms, K, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_size, None, None)\n",
    "\n",
    "    np.savez(\n",
    "        INTRINSICS_PATH,\n",
    "        rms=float(rms),\n",
    "        camera_matrix=K,\n",
    "        dist_coeffs=dist,\n",
    "        image_size=np.array(image_size, dtype=int),\n",
    "        pattern_size=np.array(PATTERN_SIZE, dtype=int),\n",
    "        square_length_m=float(SQUARE_M),\n",
    "        board_outer_mm=float(BOARD_OUTER_MM),\n",
    "        cam_base=str(CAM_BASE),\n",
    "    )\n",
    "\n",
    "    print(\"Saved intrinsics to\", INTRINSICS_PATH)\n",
    "    print(\"RMS reprojection error:\", float(rms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f4925",
   "metadata": {},
   "source": [
    "# Block 3 — Undistortion sanity check (2×2 mosaic)\n",
    "\n",
    "## Purpose\n",
    "Visual diagnostic to verify intrinsics produce sensible undistortion:\n",
    "- RAW frame\n",
    "- UNDISTORTED frame (using `cv2.getOptimalNewCameraMatrix` + `cv2.undistort`)\n",
    "- ABS DIFF (pixel difference magnitude)\n",
    "- HOTSPOTS overlay (regions where undistortion changes pixels a lot)\n",
    "\n",
    "## Preconditions\n",
    "- `SHOW_COMPARISON=True`\n",
    "- `K` and `dist` must already be defined (i.e., Block 2 has been run successfully)\n",
    "\n",
    "## How to execute\n",
    "- Choose source:\n",
    "  - `SOURCE=\"phone_url\"` uses `open_phone_cap()`\n",
    "  - `SOURCE=\"device\"` uses local webcam\n",
    "- ESC to quit\n",
    "\n",
    "## Interpreting output\n",
    "- Some diff/hotspots near edges is normal (lens distortion strongest there)\n",
    "- If hotspots dominate the whole image, intrinsics likely don’t match the actual camera source\n",
    "  - e.g., calibrated on phone but viewing laptop webcam, or vice versa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3d1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_COMPARISON:\n",
    "    # Assumes: K, dist already exist (and match the camera you open here)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Choose ONE source\n",
    "    # ----------------------------\n",
    "    SOURCE = \"phone_url\"      # \"device\" or \"phone_url\"\n",
    "\n",
    "    # local webcam (used if SOURCE=\"device\")\n",
    "    CAM_INDEX = 0\n",
    "    CAPTURE_W = 3840\n",
    "    CAPTURE_H = 2160\n",
    "\n",
    "    # phone base page (used if SOURCE=\"phone_url\")\n",
    "    CAM_BASE = CAM_BASE  # uses top-cell CAM_BASE by default\n",
    "\n",
    "    # ----------------------------\n",
    "    # Display layout\n",
    "    # ----------------------------\n",
    "    TILE_W = 640\n",
    "    TILE_H = 360\n",
    "\n",
    "    DIFF_THRESH = 25\n",
    "    BLUR_K = 5\n",
    "    ALPHA_NEWK = 0.0  # 0=crop to valid pixels (reduces black borders), 1=keep all pixels\n",
    "\n",
    "    def open_device_cap():\n",
    "        \"\"\"\n",
    "        Opens local webcam in MJPG mode at requested resolution.\n",
    "        Returns: (cap, src_string, first_frame)\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)\n",
    "        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_W)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_H)\n",
    "        if not cap.isOpened():\n",
    "            cap.release()\n",
    "            raise RuntimeError(\"Failed to open camera device\")\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            cap.release()\n",
    "            raise RuntimeError(\"Opened device camera but failed to read a frame\")\n",
    "        return cap, f\"device:{CAM_INDEX}\", frame\n",
    "\n",
    "    def resize_tile(img):\n",
    "        \"\"\"Fixed-size tiles for a 2x2 mosaic.\"\"\"\n",
    "        return cv2.resize(img, (TILE_W, TILE_H), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def label(img, text):\n",
    "        \"\"\"Readable tile labels (white text with black outline).\"\"\"\n",
    "        out = img.copy()\n",
    "        cv2.putText(out, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "        cv2.putText(out, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        return out\n",
    "\n",
    "    # ----------------------------\n",
    "    # Open selected source\n",
    "    # ----------------------------\n",
    "    if SOURCE == \"phone_url\":\n",
    "        cap, chosen_url, first = open_phone_cap()\n",
    "        src = f\"phone:{chosen_url}\"\n",
    "    elif SOURCE == \"device\":\n",
    "        cap, src, first = open_device_cap()\n",
    "    else:\n",
    "        raise ValueError('SOURCE must be \"phone_url\" or \"device\"')\n",
    "\n",
    "    print(\"ESC=quit | source:\", src)\n",
    "\n",
    "    # Cache newK by frame size.\n",
    "    newK = None\n",
    "    last_size = None\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or frame is None:\n",
    "            break\n",
    "\n",
    "        # ----------------------------\n",
    "        # Undistort with an optimal new camera matrix (newK)\n",
    "        # ----------------------------\n",
    "        # getOptimalNewCameraMatrix chooses a new projection matrix that trades off:\n",
    "        #   - cropping away invalid pixels (alpha=0)\n",
    "        #   - vs keeping all pixels (alpha=1) which may add black borders\n",
    "        h, w = frame.shape[:2]\n",
    "        if newK is None or last_size != (w, h):\n",
    "            newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), ALPHA_NEWK)\n",
    "            last_size = (w, h)\n",
    "\n",
    "        und = cv2.undistort(frame, K, dist, None, newK)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Diff view: where undistortion changes pixels the most\n",
    "        # ----------------------------\n",
    "        g_raw = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        g_und = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        diff = cv2.absdiff(g_raw, g_und)\n",
    "\n",
    "        # Optional blur to reduce speckle in diff/hotspot mask.\n",
    "        if BLUR_K and BLUR_K > 0:\n",
    "            k = BLUR_K if (BLUR_K % 2 == 1) else (BLUR_K + 1)\n",
    "            diff = cv2.GaussianBlur(diff, (k, k), 0)\n",
    "\n",
    "        diff_color = cv2.applyColorMap(diff, cv2.COLORMAP_TURBO)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Hotspot mask: threshold + morphology + overlay\n",
    "        # ----------------------------\n",
    "        mask = (diff >= DIFF_THRESH).astype(np.uint8) * 255\n",
    "        k5 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k5)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, k5)\n",
    "\n",
    "        overlay = und.copy()\n",
    "        m = (mask > 0)\n",
    "\n",
    "        # Blend red into hotspot pixels (same math as your code).\n",
    "        if m.any():\n",
    "            over_f = overlay.astype(np.float32)\n",
    "            red = np.array([0, 0, 255], dtype=np.float32)\n",
    "            over_f[m] = 0.6 * over_f[m] + 0.4 * red\n",
    "            overlay = over_f.astype(np.uint8)\n",
    "\n",
    "        hotspot_pct = 100.0 * float(np.count_nonzero(mask)) / float(mask.size)\n",
    "        overlay = label(overlay, f\"hotspots: {hotspot_pct:.2f}%\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # 2x2 mosaic\n",
    "        # ----------------------------\n",
    "        raw_t  = label(resize_tile(frame),      \"RAW\")\n",
    "        und_t  = label(resize_tile(und),        \"UNDISTORTED\")\n",
    "        diff_t = label(resize_tile(diff_color), \"ABS DIFF\")\n",
    "        over_t = label(resize_tile(overlay),    \"HOTSPOTS\")\n",
    "\n",
    "        top = np.hstack([raw_t, und_t])\n",
    "        bot = np.hstack([diff_t, over_t])\n",
    "        mosaic = np.vstack([top, bot])\n",
    "\n",
    "        cv2.imshow(\"Calibration Sanity Check\", mosaic)\n",
    "\n",
    "        if (cv2.waitKey(1) & 0xFF) == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf0153",
   "metadata": {},
   "source": [
    "# Block 4 — Live measurement on chessboard plane (click 4 points → mm)\n",
    "\n",
    "## Purpose\n",
    "Runs an interactive measurement tool:\n",
    "- Opens camera (phone stream first, otherwise webcam)\n",
    "- Undistorts frames using saved intrinsics (`K`, `dist`)\n",
    "- Maintains a stable chessboard pose estimate using:\n",
    "  - periodic full re-detection (anchors)\n",
    "  - LK optical-flow tracking between detections (stability)\n",
    "  - forward-backward + max-jump gating (prevents blowups)\n",
    "  - EMA smoothing of corners (reduces jitter)\n",
    "  - RANSAC homography (robust to a few bad points)\n",
    "- You click 4 points; if the board pose is valid, points are mapped to board-plane meters and width/height reported in mm\n",
    "\n",
    "## Controls\n",
    "- Left-click: add point / drag nearest existing point\n",
    "- Right-click: toggle zoom window (use zoom to place points precisely)\n",
    "- C: clear points\n",
    "- P: print last measurement\n",
    "- ESC: quit\n",
    "\n",
    "## Preconditions\n",
    "- `INTRINSICS_PATH` must exist and correspond to the camera you’re using\n",
    "- Chessboard must be visible enough for detection (`PATTERN_SIZE`, `SQUARE_M` must match the real board)\n",
    "\n",
    "## Output behavior\n",
    "- Overlay shows:\n",
    "  - board: OK / NOT FOUND\n",
    "  - points: N/4\n",
    "  - last measured W/H in mm (once 4 points are set and board pose is valid)\n",
    "- On exit:\n",
    "  - Raises if no measurement captured (no valid board + 4 points)\n",
    "  - Prints final measured width/height (mm)\n",
    "\n",
    "## Common failure modes\n",
    "- board stays NOT FOUND:\n",
    "  - improve contrast, reduce glare, fill more frame, hold steadier\n",
    "  - consider lowering `DETECT_EVERY_N` (more frequent re-detection) or increasing `DETECT_SCALE` (less downscale)\n",
    "- occasional pose “snaps”:\n",
    "  - tighten gating (`FB_ERR_MAX_PX`, `MAX_JUMP_PX`) or increase `TRACK_MIN_FRAC`\n",
    "  - increase smoothing slightly (`CORNER_EMA_ALPHA`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC=quit | C=clear | P=print | RClick toggle zoom | source: phone:http://192.168.1.70:8080/video\n",
      "ESC=quit | C=clear | P=print | RClick toggle zoom\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Purpose\n",
    "# ----------------------------\n",
    "# Live measurement:\n",
    "#   - Open camera (phone stream if available, else local webcam)\n",
    "#   - Undistort frames using saved intrinsics (K, dist)\n",
    "#   - Keep a stable chessboard pose estimate:\n",
    "#       * Periodic re-detection of all corners (anchors the solution)\n",
    "#       * Per-frame LK optical-flow tracking in between detections (reduces jitter)\n",
    "#       * Robust gating (prevents “collapse to center” / “shoot off” failures)\n",
    "#       * EMA smoothing of corner positions before computing homography (reduces jitter)\n",
    "#       * RANSAC homography fit (a few bad points won’t trash H)\n",
    "#   - You click 4 points; if board pose is valid, those 4 points are mapped to the board\n",
    "#     plane (meters) and width/height are reported.\n",
    "\n",
    "# ----------------------------\n",
    "# Runtime state\n",
    "# ----------------------------\n",
    "zoom_on = False\n",
    "zoom_center = None\n",
    "zoom_win = \"zoom\"\n",
    "\n",
    "pts = []            # clicked points in FULL-RES undistorted image coords (float x,y)\n",
    "drag_i = None\n",
    "cycle_i = 0\n",
    "last_dims_m = None\n",
    "\n",
    "newK = None\n",
    "last_size = None\n",
    "\n",
    "_last_zoom_origin = None\n",
    "_frame_i = 0\n",
    "\n",
    "# Board / homography state (FULL-RES undistorted image coords)\n",
    "_have_H = False\n",
    "_Hinv = None\n",
    "\n",
    "# Corner state (N = PATTERN_SIZE[0] * PATTERN_SIZE[1])\n",
    "_corners_full = None         # latest accepted corners (N,1,2) float32\n",
    "_corners_smooth = None       # EMA-smoothed corners (N,1,2) float32\n",
    "_prev_gray = None            # previous undistorted grayscale for LK tracking\n",
    "\n",
    "# ----------------------------\n",
    "# Load intrinsics\n",
    "# ----------------------------\n",
    "z = np.load(INTRINSICS_PATH, allow_pickle=True)\n",
    "K = z[\"camera_matrix\"]\n",
    "dist = z[\"dist_coeffs\"]\n",
    "\n",
    "# ----------------------------\n",
    "# Open camera (AUTO: phone stream else local webcam)\n",
    "# ----------------------------\n",
    "def _open_device():\n",
    "    cap = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_W)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_H)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        return None, None\n",
    "    ok, frame = cap.read()\n",
    "    if not ok or frame is None or frame.size == 0:\n",
    "        cap.release()\n",
    "        return None, None\n",
    "    return cap, frame\n",
    "\n",
    "def open_cam_auto():\n",
    "    # Try phone stream first (open_phone_cap() comes from your shared top cell)\n",
    "    try:\n",
    "        cap, url, frame = open_phone_cap()\n",
    "        return cap, f\"phone:{url}\", frame\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback to local device camera\n",
    "    cap2, frame2 = _open_device()\n",
    "    if cap2 is not None:\n",
    "        return cap2, f\"device:{CAM_INDEX}\", frame2\n",
    "\n",
    "    raise RuntimeError(\"Couldn't open phone stream OR local webcam.\")\n",
    "\n",
    "cap, src, first = open_cam_auto()\n",
    "print(\"ESC=quit | C=clear | P=print | RClick toggle zoom | source:\", src)\n",
    "\n",
    "# ----------------------------\n",
    "# Geometry / drawing helpers\n",
    "# ----------------------------\n",
    "def compute_display_scale(h, w):\n",
    "    # Display scaling only; all computations remain in full-res coordinates.\n",
    "    return min(DISPLAY_MAX_W / w, DISPLAY_MAX_H / h, 1.0)\n",
    "\n",
    "def to_full_res(x, y, scale):\n",
    "    # Mouse coords (display) -> full-res coords (undistorted frame space)\n",
    "    return int(x / scale), int(y / scale)\n",
    "\n",
    "def to_disp(x_full, y_full, scale):\n",
    "    # Full-res coords -> display coords\n",
    "    return int(x_full * scale), int(y_full * scale)\n",
    "\n",
    "def nearest_point_index_full(x, y, pts_list, r=POINT_HIT_R_FULL):\n",
    "    # Find nearest clicked point within hit radius (full-res coordinates)\n",
    "    if not pts_list:\n",
    "        return None\n",
    "    p = np.asarray(pts_list, dtype=np.float32)\n",
    "    d2 = (p[:, 0] - x) ** 2 + (p[:, 1] - y) ** 2\n",
    "    i = int(np.argmin(d2))\n",
    "    return i if d2[i] <= r * r else None\n",
    "\n",
    "def order_quad(pts4):\n",
    "    # Stable ordering for drawing/measuring: sort by angle around centroid, then rotate so top-left is first\n",
    "    pts4 = np.asarray(pts4, dtype=np.float32)\n",
    "    c = pts4.mean(axis=0)\n",
    "    ang = np.arctan2(pts4[:, 1] - c[1], pts4[:, 0] - c[0])\n",
    "    pts4 = pts4[np.argsort(ang)]\n",
    "    s = pts4.sum(axis=1)\n",
    "    i0 = int(np.argmin(s))\n",
    "    return np.roll(pts4, -i0, axis=0)\n",
    "\n",
    "def quad_wh_m(world_xy4):\n",
    "    # Compute width/height as avg of opposite edges in board-plane metric coords\n",
    "    p = np.asarray(world_xy4, dtype=np.float64)\n",
    "    d01 = np.linalg.norm(p[1] - p[0])\n",
    "    d12 = np.linalg.norm(p[2] - p[1])\n",
    "    d23 = np.linalg.norm(p[3] - p[2])\n",
    "    d30 = np.linalg.norm(p[0] - p[3])\n",
    "    w = 0.5 * (d01 + d23)\n",
    "    h = 0.5 * (d12 + d30)\n",
    "    return w, h\n",
    "\n",
    "def zoom_crop_bounds(img_shape, center_xy, radius):\n",
    "    h, w = img_shape[:2]\n",
    "    cx, cy = center_xy\n",
    "    x1 = max(0, cx - radius); x2 = min(w, cx + radius)\n",
    "    y1 = max(0, cy - radius); y2 = min(h, cy + radius)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def make_zoom_view(img_bgr, center_xy, radius, factor):\n",
    "    # Crop around zoom_center in full-res, then scale up by zoom_factor for a zoom window\n",
    "    x1, y1, x2, y2 = zoom_crop_bounds(img_bgr.shape, center_xy, radius)\n",
    "    crop = img_bgr[y1:y2, x1:x2].copy()\n",
    "    if crop.size == 0:\n",
    "        return None, None\n",
    "    zoom = cv2.resize(crop, None, fx=factor, fy=factor, interpolation=cv2.INTER_NEAREST)\n",
    "    zh, zw = zoom.shape[:2]\n",
    "    cv2.line(zoom, (zw // 2, 0), (zw // 2, zh), (0, 255, 0), 1)\n",
    "    cv2.line(zoom, (0, zh // 2), (zw, zh // 2), (0, 255, 0), 1)\n",
    "    return zoom, (x1, y1)\n",
    "\n",
    "def draw_marker(img, x, y, color=(0, 255, 0), ring_r=POINT_RING_R, ring_th=POINT_RING_TH, center_r=POINT_CENTER_R):\n",
    "    # Hollow ring + center dot marker; size is in screen pixels (constant in main + zoom)\n",
    "    x = int(round(x)); y = int(round(y))\n",
    "    cv2.circle(img, (x, y), ring_r, color, ring_th, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, (x, y), center_r, color, -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "def draw_text(img, lines, x=18, y=40, dy=34):\n",
    "    # White text with black outline for readability\n",
    "    for i, s in enumerate(lines):\n",
    "        yy = y + i * dy\n",
    "        cv2.putText(img, s, (x, yy), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 0), 5)\n",
    "        cv2.putText(img, s, (x, yy), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (255, 255, 255), 2)\n",
    "\n",
    "# ----------------------------\n",
    "# Mouse callbacks\n",
    "# ----------------------------\n",
    "main_win = \"Measure: LClick add/drag | RClick zoom toggle | C clear | P print | ESC quit\"\n",
    "\n",
    "def mouse_zoom(event, x, y, flags, param):\n",
    "    # Zoom window mouse uses zoom-factor mapping back to full-res coords\n",
    "    global pts, drag_i, cycle_i, zoom_on, zoom_center, _last_zoom_origin\n",
    "\n",
    "    if not zoom_on or zoom_center is None or _last_zoom_origin is None:\n",
    "        return\n",
    "\n",
    "    ox, oy = _last_zoom_origin\n",
    "    fx = float(ox + (x / zoom_factor))\n",
    "    fy = float(oy + (y / zoom_factor))\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        zoom_on = False\n",
    "        zoom_center = None\n",
    "        try:\n",
    "            cv2.destroyWindow(zoom_win)\n",
    "        except:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        i = nearest_point_index_full(fx, fy, pts, r=POINT_HIT_R_FULL)\n",
    "        if i is not None:\n",
    "            drag_i = i\n",
    "            pts[drag_i] = (fx, fy)\n",
    "            return\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            drag_i = cycle_i\n",
    "            cycle_i = (cycle_i + 1) % 4\n",
    "            pts[drag_i] = (fx, fy)\n",
    "            return\n",
    "\n",
    "        if len(pts) < 4:\n",
    "            pts.append((fx, fy))\n",
    "            return\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drag_i is not None:\n",
    "            pts[drag_i] = (fx, fy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drag_i = None\n",
    "\n",
    "def mouse_main(event, x, y, flags, param):\n",
    "    # Main window mouse: add/drag points; right click toggles zoom\n",
    "    global pts, drag_i, cycle_i, zoom_on, zoom_center, disp_scale\n",
    "\n",
    "    fx, fy = to_full_res(x, y, disp_scale)\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        if not zoom_on:\n",
    "            zoom_center = (fx, fy)\n",
    "            zoom_on = True\n",
    "            cv2.namedWindow(zoom_win)\n",
    "            cv2.setMouseCallback(zoom_win, mouse_zoom)\n",
    "        else:\n",
    "            zoom_on = False\n",
    "            zoom_center = None\n",
    "            try:\n",
    "                cv2.destroyWindow(zoom_win)\n",
    "            except:\n",
    "                pass\n",
    "        return\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        i = nearest_point_index_full(fx, fy, pts, r=POINT_HIT_R_FULL)\n",
    "\n",
    "        if i is not None:\n",
    "            drag_i = i\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "            return\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            drag_i = cycle_i\n",
    "            cycle_i = (cycle_i + 1) % 4\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "            return\n",
    "\n",
    "        if len(pts) < 4:\n",
    "            pts.append((float(fx), float(fy)))\n",
    "            return\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drag_i is not None:\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drag_i = None\n",
    "\n",
    "cv2.namedWindow(main_win)\n",
    "cv2.setMouseCallback(main_win, mouse_main)\n",
    "\n",
    "# ----------------------------\n",
    "# Chessboard detection setup\n",
    "# ----------------------------\n",
    "# world_xy: board-plane coordinates of each inner corner in meters (same indexing as OpenCV detection output)\n",
    "nx, ny = PATTERN_SIZE\n",
    "world_xy = (np.mgrid[0:nx, 0:ny].T.reshape(-1, 2).astype(np.float32) * float(SQUARE_M))\n",
    "\n",
    "SB_FLAGS = (cv2.CALIB_CB_EXHAUSTIVE | cv2.CALIB_CB_ACCURACY)\n",
    "CLASSIC_FLAGS = (cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "term = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8)) if CLAHE_ON else None\n",
    "\n",
    "def detect_board_fast(gray_full):\n",
    "    # Detect corners on a downscaled image for speed, then scale coordinates back up.\n",
    "    if DETECT_SCALE != 1.0:\n",
    "        g = cv2.resize(gray_full, (0, 0), fx=DETECT_SCALE, fy=DETECT_SCALE, interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        g = gray_full\n",
    "\n",
    "    # CLAHE improves local contrast; helps on phone streams / glarey boards.\n",
    "    g1 = clahe.apply(g) if clahe is not None else g\n",
    "\n",
    "    # Prefer SB detector (more robust); try normal then inverted.\n",
    "    if SB_FIRST:\n",
    "        ok, corners = cv2.findChessboardCornersSB(g1, PATTERN_SIZE, SB_FLAGS)\n",
    "        if ok:\n",
    "            corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "            return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "        ok, corners = cv2.findChessboardCornersSB(255 - g1, PATTERN_SIZE, SB_FLAGS)\n",
    "        if ok:\n",
    "            corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "            return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Fallback classic detector (less robust), with subpixel refinement.\n",
    "    ok, corners = cv2.findChessboardCorners(g1, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "    if ok:\n",
    "        corners = cv2.cornerSubPix(g1, corners, (11, 11), (-1, -1), term)\n",
    "        corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "        return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    ok, corners = cv2.findChessboardCorners(255 - g1, PATTERN_SIZE, CLASSIC_FLAGS)\n",
    "    if ok:\n",
    "        corners = cv2.cornerSubPix(255 - g1, corners, (11, 11), (-1, -1), term)\n",
    "        corners = corners.reshape(-1, 2) / DETECT_SCALE\n",
    "        return corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    return None\n",
    "\n",
    "# ----------------------------\n",
    "# Corner tracking (LK) + gating + smoothing + robust homography\n",
    "# ----------------------------\n",
    "# This is the part that prevents:\n",
    "#   - “collapse to middle then expand”\n",
    "#   - “one frame shoots corners far away”\n",
    "#   - jitter from small frame-to-frame corner noise\n",
    "#\n",
    "# Approach:\n",
    "#   * If we already have corners, track them frame-to-frame with LK.\n",
    "#   * Validate tracks with forward-backward consistency + max jump.\n",
    "#   * If too many corners are bad, declare tracking failed and re-detect (if enabled).\n",
    "#   * Smooth accepted corners with EMA.\n",
    "#   * Fit homography with RANSAC and invert it (image -> world).\n",
    "\n",
    "N_CORNERS = int(PATTERN_SIZE[0] * PATTERN_SIZE[1])\n",
    "MIN_GOOD_COUNT = int(np.ceil(float(TRACK_MIN_FRAC) * N_CORNERS))\n",
    "\n",
    "LK_WIN = (21, 21)\n",
    "LK_MAX_LEVEL = 3\n",
    "LK_CRIT = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)\n",
    "\n",
    "FB_ERR_MAX_PX = 1.25   # forward-backward error threshold (pixels)\n",
    "MAX_JUMP_PX = 30.0     # max per-corner displacement per frame (pixels)\n",
    "\n",
    "def ema_corners(prev_smooth, new_corners, alpha):\n",
    "    # EMA in coordinate space; preserves corner ordering and reduces jitter.\n",
    "    if prev_smooth is None:\n",
    "        return new_corners.copy()\n",
    "    a = float(alpha)\n",
    "    return ((1.0 - a) * prev_smooth + a * new_corners).astype(np.float32)\n",
    "\n",
    "def track_corners_robust(prev_gray, gray, corners_prev):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      corners_next (N,1,2) float32  OR  None if tracking is considered failed\n",
    "      good_mask    (N,) bool\n",
    "    \"\"\"\n",
    "    p0 = corners_prev.reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # Forward track: prev -> curr\n",
    "    p1, st1, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        prev_gray, gray, p0, None,\n",
    "        winSize=LK_WIN, maxLevel=LK_MAX_LEVEL, criteria=LK_CRIT,\n",
    "        flags=0, minEigThreshold=1e-4\n",
    "    )\n",
    "    if p1 is None or st1 is None:\n",
    "        return None, None\n",
    "\n",
    "    # Backward track: curr -> prev (for forward-backward check)\n",
    "    p0b, st2, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        gray, prev_gray, p1, None,\n",
    "        winSize=LK_WIN, maxLevel=LK_MAX_LEVEL, criteria=LK_CRIT,\n",
    "        flags=0, minEigThreshold=1e-4\n",
    "    )\n",
    "    if p0b is None or st2 is None:\n",
    "        return None, None\n",
    "\n",
    "    st1 = st1.reshape(-1).astype(bool)\n",
    "    st2 = st2.reshape(-1).astype(bool)\n",
    "\n",
    "    p0_xy = p0.reshape(-1, 2)\n",
    "    p1_xy = p1.reshape(-1, 2)\n",
    "    p0b_xy = p0b.reshape(-1, 2)\n",
    "\n",
    "    fb_err = np.linalg.norm(p0_xy - p0b_xy, axis=1)       # how consistent is the track?\n",
    "    disp = np.linalg.norm(p1_xy - p0_xy, axis=1)          # how far did it move this frame?\n",
    "\n",
    "    good = st1 & st2 & (fb_err <= float(FB_ERR_MAX_PX)) & (disp <= float(MAX_JUMP_PX))\n",
    "    good_n = int(good.sum())\n",
    "\n",
    "    # Not enough reliable points -> treat as failed tracking\n",
    "    if good_n < MIN_GOOD_COUNT:\n",
    "        return None, good\n",
    "\n",
    "    # Preserve ordering: any “bad” corner stays at previous location instead of poisoning H\n",
    "    p1_fix = p1.copy()\n",
    "    if (~good).any():\n",
    "        p1_fix.reshape(-1, 2)[~good] = p0_xy[~good]\n",
    "\n",
    "    return p1_fix.astype(np.float32), good\n",
    "\n",
    "def update_hinv_from_corners(corners_full):\n",
    "    \"\"\"\n",
    "    Computes H(world->image) with RANSAC, then stores Hinv(image->world).\n",
    "    RANSAC prevents a small number of remaining bad points from collapsing H.\n",
    "    \"\"\"\n",
    "    global _have_H, _Hinv\n",
    "\n",
    "    if corners_full is None:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    img_pts = corners_full.reshape(-1, 2).astype(np.float32)\n",
    "\n",
    "    H_world_to_img, inliers = cv2.findHomography(\n",
    "        world_xy, img_pts, method=cv2.RANSAC, ransacReprojThreshold=2.0\n",
    "    )\n",
    "    if H_world_to_img is None or inliers is None:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    # Require enough inliers to trust the pose\n",
    "    if int(inliers.sum()) < MIN_GOOD_COUNT:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        _Hinv = np.linalg.inv(H_world_to_img)\n",
    "    except np.linalg.LinAlgError:\n",
    "        _have_H = False\n",
    "        _Hinv = None\n",
    "        return\n",
    "\n",
    "    _have_H = True\n",
    "\n",
    "# ----------------------------\n",
    "# Main loop\n",
    "# ----------------------------\n",
    "print(\"ESC=quit | C=clear | P=print | RClick toggle zoom\")\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok or frame is None:\n",
    "        break\n",
    "\n",
    "    # (1) Undistort\n",
    "    h, w = frame.shape[:2]\n",
    "    if newK is None or last_size != (w, h):\n",
    "        # newK is a per-resolution projection that makes undistortion stable (cached)\n",
    "        newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), 1)\n",
    "        last_size = (w, h)\n",
    "\n",
    "    und = cv2.undistort(frame, K, dist, None, newK)\n",
    "    gray = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # (2) Update board pose:\n",
    "    #     - re-detect periodically (anchors)\n",
    "    #     - otherwise track from previous frame (stability)\n",
    "    need_detect = (_corners_full is None) or ((_frame_i % DETECT_EVERY_N) == 0)\n",
    "\n",
    "    if not need_detect and _prev_gray is not None and _corners_full is not None:\n",
    "        tracked_corners, good_mask = track_corners_robust(_prev_gray, gray, _corners_full)\n",
    "\n",
    "        if tracked_corners is None:\n",
    "            # Tracking failed hard (too many bad corners)\n",
    "            if REDETECT_ON_TRACK_FAIL:\n",
    "                need_detect = True\n",
    "            else:\n",
    "                _have_H = False\n",
    "                _Hinv = None\n",
    "        else:\n",
    "            # Tracking succeeded -> smooth -> update homography\n",
    "            _corners_full = tracked_corners\n",
    "            _corners_smooth = ema_corners(_corners_smooth, _corners_full, CORNER_EMA_ALPHA)\n",
    "            update_hinv_from_corners(_corners_smooth)\n",
    "\n",
    "    if need_detect:\n",
    "        detected = detect_board_fast(gray)\n",
    "        if detected is not None:\n",
    "            _corners_full = detected\n",
    "            _corners_smooth = ema_corners(_corners_smooth, _corners_full, CORNER_EMA_ALPHA)\n",
    "            update_hinv_from_corners(_corners_smooth)\n",
    "        else:\n",
    "            _have_H = False\n",
    "            _Hinv = None\n",
    "\n",
    "    # Store current gray for next frame’s tracking\n",
    "    _prev_gray = gray\n",
    "\n",
    "    # (3) Display image (scaled), but keep all point math in full-res coords\n",
    "    disp_scale = compute_display_scale(und.shape[0], und.shape[1])\n",
    "    disp = und if disp_scale >= 1.0 else cv2.resize(\n",
    "        und,\n",
    "        (int(und.shape[1] * disp_scale), int(und.shape[0] * disp_scale)),\n",
    "        interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "\n",
    "    # Draw detected corners (use smoothed corners to avoid visible jitter)\n",
    "    corners_for_draw = _corners_smooth if _corners_smooth is not None else _corners_full\n",
    "    if corners_for_draw is not None:\n",
    "        corners_disp = corners_for_draw.copy()\n",
    "        corners_disp[:, 0, 0] *= disp_scale\n",
    "        corners_disp[:, 0, 1] *= disp_scale\n",
    "        cv2.drawChessboardCorners(disp, PATTERN_SIZE, corners_disp, True)\n",
    "\n",
    "    # (4) Draw clicked points + quad; compute metric dims if homography is valid\n",
    "    if len(pts) > 0:\n",
    "        for i, (x, y) in enumerate(pts):\n",
    "            dx, dy = to_disp(x, y, disp_scale)\n",
    "            draw_marker(disp, dx, dy)\n",
    "            cv2.putText(\n",
    "                disp, str(i + 1),\n",
    "                (dx + POINT_RING_R + 4, dy - POINT_RING_R - 2),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, LABEL_SCALE, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            quad = order_quad(pts)\n",
    "            quad_disp = (quad * disp_scale).astype(np.float32)\n",
    "            cv2.polylines(\n",
    "                disp, [quad_disp.astype(np.int32).reshape(-1, 1, 2)],\n",
    "                True, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            if _have_H and _Hinv is not None:\n",
    "                pts_img = quad.astype(np.float32).reshape(-1, 1, 2)\n",
    "                # perspectiveTransform expects image points; Hinv maps image->world (board plane meters)\n",
    "                pts_world = cv2.perspectiveTransform(pts_img, _Hinv).reshape(-1, 2)\n",
    "                w_m, h_m = quad_wh_m(pts_world)\n",
    "                last_dims_m = (float(w_m), float(h_m))\n",
    "\n",
    "    # (5) Status overlay\n",
    "    status = [\n",
    "        f\"board: {'OK' if _have_H else 'NOT FOUND'} | points: {len(pts)}/4 | zoom: {'ON' if zoom_on else 'OFF'}\"\n",
    "    ]\n",
    "    if last_dims_m is not None:\n",
    "        status.append(f\"W: {last_dims_m[0] * 1000.0:.1f} mm   H: {last_dims_m[1] * 1000.0:.1f} mm\")\n",
    "    else:\n",
    "        status.append(\"W: --   H: --\")\n",
    "\n",
    "    draw_text(disp, status)\n",
    "    cv2.imshow(main_win, disp)\n",
    "\n",
    "    # (6) Zoom window\n",
    "    if zoom_on:\n",
    "        if zoom_center is None:\n",
    "            zoom_center = (w // 2, h // 2)\n",
    "\n",
    "        zoom_img, origin = make_zoom_view(und, zoom_center, zoom_radius, zoom_factor)\n",
    "        _last_zoom_origin = origin\n",
    "\n",
    "        if zoom_img is not None and origin is not None:\n",
    "            ox, oy = origin\n",
    "\n",
    "            for i, (px, py) in enumerate(pts):\n",
    "                zx = int((px - ox) * zoom_factor)\n",
    "                zy = int((py - oy) * zoom_factor)\n",
    "                if 0 <= zx < zoom_img.shape[1] and 0 <= zy < zoom_img.shape[0]:\n",
    "                    draw_marker(zoom_img, zx, zy)\n",
    "                    cv2.putText(\n",
    "                        zoom_img, str(i + 1),\n",
    "                        (zx + POINT_RING_R + 4, zy - POINT_RING_R - 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, LABEL_SCALE, (0, 255, 0), 1, lineType=cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "            cv2.imshow(zoom_win, zoom_img)\n",
    "\n",
    "    # (7) Key handling\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key in (ord('c'), ord('C')):\n",
    "        pts = []\n",
    "        drag_i = None\n",
    "        cycle_i = 0\n",
    "        last_dims_m = None\n",
    "    if key in (ord('p'), ord('P')):\n",
    "        if last_dims_m is None:\n",
    "            print(\"No measurement yet (need 4 points + board found).\")\n",
    "        else:\n",
    "            print(f\"W: {last_dims_m[0] * 1000.0:.1f} mm | H: {last_dims_m[1] * 1000.0:.1f} mm\")\n",
    "\n",
    "    _frame_i += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if last_dims_m is None:\n",
    "    raise RuntimeError(\"No measurement captured (need 4 clicked points + board found).\")\n",
    "\n",
    "print(\"Measured dimensions:\")\n",
    "print(f\"  Width : {last_dims_m[0] * 1000.0:.1f} mm\")\n",
    "print(f\"  Height: {last_dims_m[1] * 1000.0:.1f} mm\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166cbca1",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "Perform the camera calibration using built-in tools in OpenCV or MATLAB – use a smartphone camera for this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c43f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_CALIBRATED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd1d2e4",
   "metadata": {},
   "source": [
    "## ChArUco Board + OpenCV Settings (Matches Printed Target)\n",
    "\n",
    "This notebook uses a **ChArUco calibration target** to estimate the camera’s intrinsic parameters (camera matrix) and lens distortion coefficients using OpenCV.\n",
    "\n",
    "### Printed board (calib.io default file)\n",
    "The printed target corresponds to:\n",
    "- **Rows × Columns:** 5 × 7 squares  \n",
    "- **Checker (square) size:** 28 mm  \n",
    "- **Marker size:** 21 mm  \n",
    "- **Dictionary:** DICT_4X4  \n",
    "\n",
    "These physical dimensions are used as **metric ground truth** during calibration.\n",
    "\n",
    "### OpenCV parameters (must match the print)\n",
    "```python\n",
    "SQUARES_X = 7\n",
    "SQUARES_Y = 5\n",
    "SQUARE_LENGTH_M = 0.028   # 28 mm\n",
    "MARKER_LENGTH_M = 0.021   # 21 mm\n",
    "DICTIONARY_ID = cv2.aruco.DICT_4X4_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf94cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "SQUARES_X = 7\n",
    "SQUARES_Y = 5\n",
    "SQUARE_LENGTH_M = 0.028   # 28 mm\n",
    "MARKER_LENGTH_M = 0.021   # 21 mm\n",
    "DICTIONARY_ID = cv2.aruco.DICT_4X4_50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706b2f7",
   "metadata": {},
   "source": [
    "## Calibration Frame Capture Step\n",
    "\n",
    "This step collects raw calibration images from the camera and saves selected frames to disk.\n",
    "\n",
    "- A directory named `calib_frames` is created to store captured images.\n",
    "- The camera is opened using the DirectShow backend to ensure stable initialization on Windows.\n",
    "- The capture resolution is fixed so all images share the same dimensions.\n",
    "- Frames are continuously read from the camera and displayed in a preview window.\n",
    "- Pressing **SPACE** saves the current frame as a PNG file with a sequential name.\n",
    "- Pressing **ESC** exits the capture loop.\n",
    "- When finished, the camera is released and all OpenCV windows are closed.\n",
    "\n",
    "The result is a set of static images that serve as input to the ChArUco detection and calibration steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2704b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "if not PRE_CALIBRATED:\n",
    "    out = Path(\"calib_frames\")\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3840)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2160)\n",
    "\n",
    "    actual_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    actual_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"Capture resolution: {actual_w}x{actual_h}\")\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        raise RuntimeError(\"Failed to open camera\")\n",
    "\n",
    "    idx = 0\n",
    "    print(\"SPACE=save | ESC=quit\")\n",
    "\n",
    "    PREVIEW_MAX_W = 1600   # fits most monitors\n",
    "    PREVIEW_MAX_H = 900\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            print(\"Frame read failed; exiting.\")\n",
    "            break\n",
    "\n",
    "        # -------- preview only (does NOT affect saved image) --------\n",
    "        preview = cv2.flip(frame, 1)  # mirror for usability\n",
    "\n",
    "        h, w = preview.shape[:2]\n",
    "        scale = min(PREVIEW_MAX_W / w, PREVIEW_MAX_H / h, 1.0)\n",
    "        if scale < 1.0:\n",
    "            preview = cv2.resize(\n",
    "                preview,\n",
    "                (int(w * scale), int(h * scale)),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        cv2.imshow(\"SPACE=save | ESC=quit\", preview)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 27:\n",
    "            print(\"ESC pressed; exiting.\")\n",
    "            break\n",
    "\n",
    "        if key == 32:\n",
    "            fname = out / f\"frame_{idx:04d}.jpg\"\n",
    "            ok_write = cv2.imwrite(\n",
    "                str(fname),\n",
    "                frame,  # ORIGINAL 4K, NOT flipped, NOT resized\n",
    "                [int(cv2.IMWRITE_JPEG_QUALITY), 95]\n",
    "            )\n",
    "            print(f\"Saved {fname}\" if ok_write else f\"Failed to save {fname}\")\n",
    "            idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"skipping\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb38fb",
   "metadata": {},
   "source": [
    "## ChArUco Detection Step\n",
    "This step processes the saved calibration images and extracts usable geometric measurements from them.\n",
    "\n",
    "- The ChArUco board geometry and ArUco dictionary are defined so OpenCV knows the physical layout of the printed target.\n",
    "- Each saved image is loaded and converted to grayscale.\n",
    "- ArUco markers are detected in the image to identify which parts of the board are visible.\n",
    "- Using the detected markers and the known board layout, OpenCV interpolates the ChArUco chessboard corner locations with subpixel accuracy.\n",
    "- Images with too few detected corners are discarded.\n",
    "- Valid corner locations and their IDs are accumulated across all images.\n",
    "\n",
    "The output of this step is a set of consistent 2D image points paired with known board points, which are then used by the camera calibration routine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f273f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "aruco_dict = cv2.aruco.getPredefinedDictionary(DICTIONARY_ID)\n",
    "board = cv2.aruco.CharucoBoard(\n",
    "    (SQUARES_X, SQUARES_Y),\n",
    "    SQUARE_LENGTH_M,\n",
    "    MARKER_LENGTH_M,\n",
    "    aruco_dict,\n",
    ")\n",
    "\n",
    "detector = cv2.aruco.ArucoDetector(\n",
    "    aruco_dict, cv2.aruco.DetectorParameters()\n",
    ")\n",
    "\n",
    "charuco_corners = []\n",
    "charuco_ids = []\n",
    "image_size = None\n",
    "\n",
    "for fname in sorted(glob.glob(\"calib_frames/*.jpg\")):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if image_size is None:\n",
    "        image_size = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "    corners, ids, _ = detector.detectMarkers(gray)\n",
    "    if ids is None:\n",
    "        continue\n",
    "\n",
    "    ok, c_corners, c_ids = cv2.aruco.interpolateCornersCharuco(\n",
    "        corners, ids, gray, board\n",
    "    )\n",
    "\n",
    "    if ok is not None and ok >= 8:\n",
    "        charuco_corners.append(c_corners)\n",
    "        charuco_ids.append(c_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43138a9f",
   "metadata": {},
   "source": [
    "## Camera Calibration Step\n",
    "\n",
    "This step estimates the camera’s intrinsic parameters and lens distortion.\n",
    "\n",
    "- `calibrateCameraCharuco` uses all detected ChArUco corner correspondences across images.\n",
    "- The function fits a pinhole camera model by minimizing reprojection error.\n",
    "- Outputs include the camera matrix (`K`), distortion coefficients (`dist`), and RMS reprojection error (`rms`).\n",
    "- Per-image board poses (`rvecs`, `tvecs`) are also computed.\n",
    "\n",
    "The results are saved to `camera_intrinsics.npz` so they can be reused for image undistortion and further processing without recalibrating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e1846b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charuco_ids: 15 charuco_corners: 15 image_size: (3840, 2160)\n"
     ]
    }
   ],
   "source": [
    "n = len(charuco_ids)\n",
    "m = len(charuco_corners)\n",
    "print(\"charuco_ids:\", n, \"charuco_corners:\", m, \"image_size:\", image_size)\n",
    "if n == 0 or m == 0:\n",
    "    raise RuntimeError(\"No usable ChArUco detections collected. Re-run detection, lower ok_i threshold, or capture clearer/closer board frames.\")\n",
    "if n != m:\n",
    "    raise RuntimeError(\"Mismatch: charuco_ids and charuco_corners lengths differ. Re-run detection from scratch.\")\n",
    "\n",
    "rms, K, dist, rvecs, tvecs = cv2.aruco.calibrateCameraCharuco(\n",
    "    charucoCorners=charuco_corners,\n",
    "    charucoIds=charuco_ids,\n",
    "    board=board,\n",
    "    imageSize=image_size,\n",
    "    cameraMatrix=None,\n",
    "    distCoeffs=None,\n",
    ")\n",
    "\n",
    "np.savez(\n",
    "    \"camera_intrinsics.npz\",\n",
    "    rms=rms,\n",
    "    camera_matrix=K,\n",
    "    dist_coeffs=dist,\n",
    "    image_size=image_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff1479",
   "metadata": {},
   "source": [
    "## Live Undistortion Check\n",
    "\n",
    "This step applies the calibrated camera parameters to a live video stream to visually verify the calibration.\n",
    "\n",
    "- A refined camera matrix is computed to account for lens distortion.\n",
    "- Each captured frame is undistorted using the calibrated intrinsics.\n",
    "- The undistorted image is displayed in real time.\n",
    "- This provides a qualitative check that distortion has been corrected.\n",
    "- No parameters are estimated or saved in this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4807657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "if not PRE_CALIBRATED:\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Camera failed to open\")\n",
    "\n",
    "    newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, image_size, 0)\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        und = cv2.undistort(frame, K, dist, None, newK)\n",
    "\n",
    "        cv2.imshow(\"original\", frame)\n",
    "        cv2.imshow(\"undistorted\", und)\n",
    "\n",
    "        if (cv2.waitKey(1) & 0xFF) == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else: print(\"skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c20af9",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "Implement in Python or MATLAB, a script to find the real world 2D dimensions of an object using perspective projection equations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eede9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.10022584880153934), np.float64(0.09538679635776284))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ---- display scaling (does NOT affect math) ----\n",
    "DISPLAY_MAX_W = 1600\n",
    "DISPLAY_MAX_H = 900\n",
    "disp_scale = 1.0\n",
    "\n",
    "def compute_display_scale(h, w):\n",
    "    return min(DISPLAY_MAX_W / w, DISPLAY_MAX_H / h, 1.0)\n",
    "\n",
    "def to_full_res(x, y, scale):\n",
    "    return int(x / scale), int(y / scale)\n",
    "\n",
    "def to_display_res(x, y, scale):\n",
    "    return int(x * scale), int(y * scale)\n",
    "\n",
    "# ---- interactive points ----\n",
    "pts = []          # 4 points in FULL-RES coordinates\n",
    "drag_i = None\n",
    "\n",
    "zoom_center = None\n",
    "zoom_on = False\n",
    "zoom_factor = 4\n",
    "zoom_radius = 170\n",
    "\n",
    "def ids_to_world_xy(ch_ids, board):\n",
    "    ids = ch_ids.reshape(-1).astype(int)\n",
    "    chess = board.getChessboardCorners()\n",
    "    return chess[ids, :2].astype(np.float32)\n",
    "\n",
    "def order_quad(pts4):\n",
    "    pts4 = np.asarray(pts4, dtype=np.float32)\n",
    "    c = pts4.mean(axis=0)\n",
    "    ang = np.arctan2(pts4[:, 1] - c[1], pts4[:, 0] - c[0])\n",
    "    pts4 = pts4[np.argsort(ang)]\n",
    "    s = pts4.sum(axis=1)\n",
    "    i0 = np.argmin(s)\n",
    "    return np.roll(pts4, -i0, axis=0)\n",
    "\n",
    "def quad_wh_m(world_xy4):\n",
    "    p = np.asarray(world_xy4, dtype=np.float64)\n",
    "    d01 = np.linalg.norm(p[1] - p[0])\n",
    "    d12 = np.linalg.norm(p[2] - p[1])\n",
    "    d23 = np.linalg.norm(p[3] - p[2])\n",
    "    d30 = np.linalg.norm(p[0] - p[3])\n",
    "    w = 0.5 * (d01 + d23)\n",
    "    h = 0.5 * (d12 + d30)\n",
    "    return w, h\n",
    "\n",
    "def make_zoom_view(img_bgr, center_xy, radius, factor):\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    cx, cy = center_xy\n",
    "    x1 = max(0, cx - radius); x2 = min(w, cx + radius)\n",
    "    y1 = max(0, cy - radius); y2 = min(h, cy + radius)\n",
    "    crop = img_bgr[y1:y2, x1:x2].copy()\n",
    "    if crop.size == 0:\n",
    "        return None\n",
    "    zoom = cv2.resize(crop, None, fx=factor, fy=factor, interpolation=cv2.INTER_NEAREST)\n",
    "    zh, zw = zoom.shape[:2]\n",
    "    cv2.line(zoom, (zw//2, 0), (zw//2, zh), (0, 255, 0), 1)\n",
    "    cv2.line(zoom, (0, zh//2), (zw, zh//2), (0, 255, 0), 1)\n",
    "    return zoom\n",
    "\n",
    "def nearest_point_index(x, y, pts_list, r=25):\n",
    "    if not pts_list:\n",
    "        return None\n",
    "    p = np.asarray(pts_list, dtype=np.float32)\n",
    "    d2 = (p[:, 0] - x)**2 + (p[:, 1] - y)**2\n",
    "    i = int(np.argmin(d2))\n",
    "    return i if d2[i] <= r*r else None\n",
    "\n",
    "def mouse_cb(event, x, y, flags, param):\n",
    "    global pts, drag_i, zoom_center, zoom_on, disp_scale\n",
    "\n",
    "    fx, fy = to_full_res(x, y, disp_scale)\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        i = nearest_point_index(fx, fy, pts, r=25)\n",
    "        if i is not None:\n",
    "            drag_i = i\n",
    "        else:\n",
    "            if len(pts) < 4:\n",
    "                pts.append((float(fx), float(fy)))\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drag_i is not None:\n",
    "            pts[drag_i] = (float(fx), float(fy))\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drag_i = None\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        zoom_center = (fx, fy)\n",
    "        zoom_on = True\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3840)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2160)\n",
    "\n",
    "win = \"Measure: LClick add/drag | RClick zoom | C clear | Z toggle zoom | ESC quit\"\n",
    "cv2.namedWindow(win)\n",
    "cv2.setMouseCallback(win, mouse_cb)\n",
    "\n",
    "last_dims_m = None\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    Hh, Ww = frame.shape[:2]\n",
    "    newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (Ww, Hh), 0)\n",
    "    und = cv2.undistort(frame, K, dist, None, newK)\n",
    "    gray = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    marker_corners, marker_ids, _ = detector.detectMarkers(gray)\n",
    "    have_H = False\n",
    "    Hinv = None\n",
    "    ch_corners = None\n",
    "    ch_ids = None\n",
    "\n",
    "    if marker_ids is not None and len(marker_ids) > 0:\n",
    "        ok_i, ch_corners, ch_ids = cv2.aruco.interpolateCornersCharuco(marker_corners, marker_ids, gray, board)\n",
    "        if ok_i is not None and ch_ids is not None and ok_i >= 4:\n",
    "            img_pts = ch_corners.reshape(-1, 2).astype(np.float32)\n",
    "            world_xy = ids_to_world_xy(ch_ids, board)\n",
    "            H_world_to_img, _ = cv2.findHomography(world_xy, img_pts, 0)\n",
    "            if H_world_to_img is not None:\n",
    "                Hinv = np.linalg.inv(H_world_to_img)\n",
    "                have_H = True\n",
    "    \n",
    "\n",
    "    vis = und.copy()\n",
    "    if ch_corners is not None and ch_ids is not None:\n",
    "        cv2.aruco.drawDetectedCornersCharuco(vis, ch_corners, ch_ids)\n",
    "\n",
    "    if len(pts) > 0:\n",
    "        for i, (x, y) in enumerate(pts):\n",
    "            dx, dy = to_display_res(x, y, 1.0)  # full-res draw on vis\n",
    "            cv2.circle(vis, (int(dx), int(dy)), 10, (0, 255, 0), -1)\n",
    "            cv2.putText(vis, str(i+1), (int(dx)+12, int(dy)-12),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,0), 2)\n",
    "\n",
    "        if len(pts) == 4:\n",
    "            quad = order_quad(pts)\n",
    "            cv2.polylines(vis, [quad.astype(np.int32).reshape(-1, 1, 2)], True, (0, 255, 0), 3)\n",
    "\n",
    "            if have_H:\n",
    "                pts_img = quad.astype(np.float32).reshape(-1, 1, 2)\n",
    "                pts_world = cv2.perspectiveTransform(pts_img, Hinv).reshape(-1, 2)\n",
    "                w_m, h_m = quad_wh_m(pts_world)\n",
    "                last_dims_m = (w_m, h_m)\n",
    "                cv2.putText(vis, f\"W: {w_m*1000:.1f} mm\", (30, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255,255,255), 3)\n",
    "                cv2.putText(vis, f\"H: {h_m*1000:.1f} mm\", (30, 120),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255,255,255), 3)\n",
    "            else:\n",
    "                cv2.putText(vis, \"Need ChArUco in view for scale.\", (30, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 3)\n",
    "\n",
    "    # scale for display only\n",
    "    disp_scale = compute_display_scale(vis.shape[0], vis.shape[1])\n",
    "    disp = vis\n",
    "    if disp_scale < 1.0:\n",
    "        disp = cv2.resize(vis, (int(vis.shape[1]*disp_scale), int(vis.shape[0]*disp_scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    status = f\"pts={len(pts)}  ok_i={int(ok_i) if ok_i is not None else -1}  have_H={have_H}\"\n",
    "    cv2.putText(disp, status, (20, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(win, disp)\n",
    "\n",
    "    if zoom_on and zoom_center is not None:\n",
    "        zoom_img = make_zoom_view(vis, zoom_center, zoom_radius, zoom_factor)\n",
    "        if zoom_img is not None:\n",
    "            cv2.imshow(\"zoom\", zoom_img)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key in (ord('c'), ord('C')):\n",
    "        pts = []\n",
    "        last_dims_m = None\n",
    "    if key in (ord('z'), ord('Z')):\n",
    "        zoom_on = not zoom_on\n",
    "        if not zoom_on:\n",
    "            cv2.destroyWindow(\"zoom\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "w_mm = last_dims_m[0] * 1000\n",
    "h_mm = last_dims_m[1] * 1000\n",
    "\n",
    "print(f\"Measured dimensions:\")\n",
    "print(f\"  Width : {w_mm:.1f} mm\")\n",
    "print(f\"  Height: {h_mm:.1f} mm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07b033fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3840)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a5330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840 2160\n"
     ]
    }
   ],
   "source": [
    "actual_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "actual_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(actual_w, actual_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb851781",
   "metadata": {},
   "source": [
    "# Part 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e049e54b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# assumes: K, dist, board, detector already exist\u001b[39;00m\n\u001b[32m      3\u001b[39m img = cv2.imread(\u001b[33m\"\u001b[39m\u001b[33mphoto.jpg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m h, w = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m[:\u001b[32m2\u001b[39m]\n\u001b[32m      5\u001b[39m newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), \u001b[32m0\u001b[39m)\n\u001b[32m      6\u001b[39m und = cv2.undistort(img, K, dist, \u001b[38;5;28;01mNone\u001b[39;00m, newK)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# assumes: K, dist, board, detector already exist\n",
    "\n",
    "img = cv2.imread(\"photo.jpg\")\n",
    "h, w = img.shape[:2]\n",
    "newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), 0)\n",
    "und = cv2.undistort(img, K, dist, None, newK)\n",
    "gray = cv2.cvtColor(und, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "m_corners, m_ids, _ = detector.detectMarkers(gray)\n",
    "ok_i, ch_corners, ch_ids = cv2.aruco.interpolateCornersCharuco(m_corners, m_ids, gray, board)\n",
    "\n",
    "img_pts = ch_corners.reshape(-1, 2).astype(np.float32)\n",
    "world_xy = board.getChessboardCorners()[ch_ids.reshape(-1).astype(int), :2].astype(np.float32)\n",
    "\n",
    "H, _ = cv2.findHomography(world_xy, img_pts, 0)\n",
    "Hinv = np.linalg.inv(H)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
